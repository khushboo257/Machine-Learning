{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayurbohra9/Machine-Learning-CS-601/blob/main/Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "# Joint Online Faculty Development programme on Deep Learning (Parallel Architecture) Aug 23 â€“ Sep 3 , 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrZg_G5MQ4L5",
        "outputId": "ad957c76-6a84-497c-e8be-1996acf48cba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjgG_3CiP4eQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a84029e3-a5da-486b-eecd-79aaa61895ac"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820459fe-d3fe-4ff1-a572-4efa1ad46b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Alexa skill set-WPS Office.docx'\n",
            " Certificates\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            " Colab_Notebooks\n",
            "'Copy of CO-G9 local shopping site synopsis.docx'\n",
            " custom_trainvalacc.png\n",
            " custom_trainvalloss.png\n",
            "'Cybersecurity_Foundation_Student_Certificate Vedant Jain.pdf'\n",
            " diabetes.csv\n",
            " Documents\n",
            "'Event Feedback.gform'\n",
            "'Event Feedback (Responses).gsheet'\n",
            "'Internet and web technologies - Vedant jain CO-62 folder'\n",
            "'Lab analysis.docx'\n",
            "'Linux Lab work.gdoc'\n",
            "'LINUX - Vedant jain CO-62 folder'\n",
            "'project works'\n",
            "'R Assignment 1.gdoc'\n",
            "'Screenshot (374).png'\n",
            " STU6045b97f77e1a1615182207.pdf\n",
            " testing_1-alexa-model.json\n",
            "'TOC vedant jain CO-62.docx'\n",
            "'Untitled document - Pie chart 1.gsheet'\n",
            "'Vedant jain CO62 IWT unit test .pdf'\n",
            "'Vedant jain CO-62 Linux file.docx'\n",
            "'Vedant Jain CO-62 TOC Practical assesment-converted.docx'\n",
            "'vedant jain CO-62 TOC UT.pdf'\n",
            "'Vedant Jain_resume.pdf'\n",
            " voiceflow-export-1640929946598.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fb6cfUjeNLF5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "32nNonRSSaQq",
        "outputId": "fc4605c9-d473-48c2-923e-ba256cdbf515"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cbf66f9-0989-48fb-8032-c8d0f0580433\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cbf66f9-0989-48fb-8032-c8d0f0580433')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cbf66f9-0989-48fb-8032-c8d0f0580433 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cbf66f9-0989-48fb-8032-c8d0f0580433');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "aa5c7a33-bd31-4209-8eab-13b0bc93f1ef"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "1e200f53-b1b4-4484-cdd3-c07dbc987834"
      },
      "source": [
        "data.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "88356ec5-0305-4412-e73f-97fdfa75ca79"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "ffe2c5a9-0e18-4cc8-f657-716a13a1aa75"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "2acc2f05-c67a-4a5f-ce0f-4c6904ee0be2"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "4e664014-51e2-46a9-8ae1-93c8ba89b286"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNfmvbMOXeku",
        "outputId": "cea031d0-0349-4db7-9a90-2675a5da7342"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(16, activation='tanh'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 24)                216       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 20)                500       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 16)                336       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 12)                204       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378\n",
            "Trainable params: 1,378\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "e5b1e093-8f16-45b7-aa41-efa9d73b5ce0"
      },
      "source": [
        "list = model.fit(X_training, Y_training,batch_size=2,  epochs=1000, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "246/246 [==============================] - 2s 5ms/step - loss: 0.6379 - accuracy: 0.6680 - val_loss: 0.6432 - val_accuracy: 0.6260\n",
            "Epoch 2/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.6158 - accuracy: 0.6680 - val_loss: 0.6241 - val_accuracy: 0.6585\n",
            "Epoch 3/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.5930 - accuracy: 0.6823 - val_loss: 0.5812 - val_accuracy: 0.7236\n",
            "Epoch 4/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.5589 - accuracy: 0.7189 - val_loss: 0.5456 - val_accuracy: 0.7561\n",
            "Epoch 5/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.7230 - val_loss: 0.5481 - val_accuracy: 0.7317\n",
            "Epoch 6/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.5144 - accuracy: 0.7291 - val_loss: 0.5120 - val_accuracy: 0.7724\n",
            "Epoch 7/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.5182 - accuracy: 0.7556 - val_loss: 0.4997 - val_accuracy: 0.7398\n",
            "Epoch 8/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.5073 - accuracy: 0.7454 - val_loss: 0.5043 - val_accuracy: 0.7561\n",
            "Epoch 9/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.5079 - accuracy: 0.7312 - val_loss: 0.4910 - val_accuracy: 0.7886\n",
            "Epoch 10/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4936 - accuracy: 0.7637 - val_loss: 0.4890 - val_accuracy: 0.7886\n",
            "Epoch 11/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4967 - accuracy: 0.7515 - val_loss: 0.4896 - val_accuracy: 0.7805\n",
            "Epoch 12/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4844 - accuracy: 0.7719 - val_loss: 0.4829 - val_accuracy: 0.7480\n",
            "Epoch 13/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4944 - accuracy: 0.7617 - val_loss: 0.4753 - val_accuracy: 0.7886\n",
            "Epoch 14/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4846 - accuracy: 0.7617 - val_loss: 0.5361 - val_accuracy: 0.7561\n",
            "Epoch 15/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4836 - accuracy: 0.7556 - val_loss: 0.5049 - val_accuracy: 0.7480\n",
            "Epoch 16/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4850 - accuracy: 0.7637 - val_loss: 0.4690 - val_accuracy: 0.7886\n",
            "Epoch 17/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4729 - accuracy: 0.7658 - val_loss: 0.4854 - val_accuracy: 0.7967\n",
            "Epoch 18/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4828 - accuracy: 0.7597 - val_loss: 0.4784 - val_accuracy: 0.7724\n",
            "Epoch 19/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4763 - accuracy: 0.7597 - val_loss: 0.4897 - val_accuracy: 0.7967\n",
            "Epoch 20/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.7678 - val_loss: 0.4967 - val_accuracy: 0.7886\n",
            "Epoch 21/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4795 - accuracy: 0.7780 - val_loss: 0.4886 - val_accuracy: 0.7642\n",
            "Epoch 22/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4805 - accuracy: 0.7719 - val_loss: 0.4718 - val_accuracy: 0.7967\n",
            "Epoch 23/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.7699 - val_loss: 0.5134 - val_accuracy: 0.7642\n",
            "Epoch 24/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.7658 - val_loss: 0.4793 - val_accuracy: 0.7724\n",
            "Epoch 25/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4790 - accuracy: 0.7699 - val_loss: 0.4834 - val_accuracy: 0.8049\n",
            "Epoch 26/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4758 - accuracy: 0.7556 - val_loss: 0.4789 - val_accuracy: 0.7642\n",
            "Epoch 27/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7719 - val_loss: 0.4795 - val_accuracy: 0.7967\n",
            "Epoch 28/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4713 - accuracy: 0.7637 - val_loss: 0.4742 - val_accuracy: 0.7967\n",
            "Epoch 29/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4669 - accuracy: 0.7699 - val_loss: 0.4778 - val_accuracy: 0.7967\n",
            "Epoch 30/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4579 - accuracy: 0.7821 - val_loss: 0.4690 - val_accuracy: 0.8130\n",
            "Epoch 31/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4708 - val_accuracy: 0.8130\n",
            "Epoch 32/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4689 - accuracy: 0.7678 - val_loss: 0.5124 - val_accuracy: 0.7642\n",
            "Epoch 33/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4620 - accuracy: 0.7678 - val_loss: 0.5507 - val_accuracy: 0.7805\n",
            "Epoch 34/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7637 - val_loss: 0.4967 - val_accuracy: 0.7642\n",
            "Epoch 35/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.5195 - val_accuracy: 0.7480\n",
            "Epoch 36/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4617 - accuracy: 0.7719 - val_loss: 0.4997 - val_accuracy: 0.7805\n",
            "Epoch 37/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7617 - val_loss: 0.5217 - val_accuracy: 0.7886\n",
            "Epoch 38/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.7821 - val_loss: 0.4841 - val_accuracy: 0.7642\n",
            "Epoch 39/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4772 - val_accuracy: 0.8049\n",
            "Epoch 40/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4588 - accuracy: 0.7678 - val_loss: 0.4979 - val_accuracy: 0.7642\n",
            "Epoch 41/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4472 - accuracy: 0.7739 - val_loss: 0.6331 - val_accuracy: 0.7480\n",
            "Epoch 42/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4569 - accuracy: 0.7617 - val_loss: 0.5721 - val_accuracy: 0.7398\n",
            "Epoch 43/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7475 - val_loss: 0.4885 - val_accuracy: 0.7886\n",
            "Epoch 44/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4540 - accuracy: 0.7739 - val_loss: 0.4911 - val_accuracy: 0.7805\n",
            "Epoch 45/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4543 - accuracy: 0.7597 - val_loss: 0.4764 - val_accuracy: 0.8130\n",
            "Epoch 46/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4458 - accuracy: 0.7699 - val_loss: 0.5112 - val_accuracy: 0.7886\n",
            "Epoch 47/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4525 - accuracy: 0.7800 - val_loss: 0.5671 - val_accuracy: 0.7724\n",
            "Epoch 48/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4513 - accuracy: 0.7719 - val_loss: 0.4956 - val_accuracy: 0.7561\n",
            "Epoch 49/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4465 - accuracy: 0.7597 - val_loss: 0.5226 - val_accuracy: 0.7480\n",
            "Epoch 50/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4508 - accuracy: 0.7800 - val_loss: 0.4882 - val_accuracy: 0.7642\n",
            "Epoch 51/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4465 - accuracy: 0.7923 - val_loss: 0.4912 - val_accuracy: 0.7724\n",
            "Epoch 52/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4515 - accuracy: 0.7597 - val_loss: 0.4908 - val_accuracy: 0.7724\n",
            "Epoch 53/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4476 - accuracy: 0.7739 - val_loss: 0.5312 - val_accuracy: 0.7398\n",
            "Epoch 54/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4422 - accuracy: 0.7658 - val_loss: 0.5002 - val_accuracy: 0.7480\n",
            "Epoch 55/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4537 - accuracy: 0.7760 - val_loss: 0.4891 - val_accuracy: 0.7805\n",
            "Epoch 56/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4366 - accuracy: 0.7780 - val_loss: 0.4964 - val_accuracy: 0.7805\n",
            "Epoch 57/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4409 - accuracy: 0.7739 - val_loss: 0.5209 - val_accuracy: 0.7561\n",
            "Epoch 58/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4411 - accuracy: 0.7862 - val_loss: 0.5059 - val_accuracy: 0.7561\n",
            "Epoch 59/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4294 - accuracy: 0.7963 - val_loss: 0.4991 - val_accuracy: 0.7886\n",
            "Epoch 60/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4348 - accuracy: 0.7739 - val_loss: 0.5076 - val_accuracy: 0.7642\n",
            "Epoch 61/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4403 - accuracy: 0.7719 - val_loss: 0.4946 - val_accuracy: 0.7724\n",
            "Epoch 62/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4329 - accuracy: 0.7923 - val_loss: 0.4924 - val_accuracy: 0.7724\n",
            "Epoch 63/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4408 - accuracy: 0.7800 - val_loss: 0.4999 - val_accuracy: 0.7561\n",
            "Epoch 64/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4409 - accuracy: 0.7862 - val_loss: 0.5184 - val_accuracy: 0.7805\n",
            "Epoch 65/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4449 - accuracy: 0.7678 - val_loss: 0.4985 - val_accuracy: 0.8049\n",
            "Epoch 66/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4345 - accuracy: 0.7841 - val_loss: 0.4929 - val_accuracy: 0.7886\n",
            "Epoch 67/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4334 - accuracy: 0.7902 - val_loss: 0.5408 - val_accuracy: 0.7886\n",
            "Epoch 68/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4214 - accuracy: 0.7943 - val_loss: 0.4933 - val_accuracy: 0.8049\n",
            "Epoch 69/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.7902 - val_loss: 0.5381 - val_accuracy: 0.7642\n",
            "Epoch 70/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4252 - accuracy: 0.7862 - val_loss: 0.5173 - val_accuracy: 0.7642\n",
            "Epoch 71/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4345 - accuracy: 0.7943 - val_loss: 0.5030 - val_accuracy: 0.7886\n",
            "Epoch 72/1000\n",
            "246/246 [==============================] - 2s 7ms/step - loss: 0.4373 - accuracy: 0.7862 - val_loss: 0.6766 - val_accuracy: 0.6098\n",
            "Epoch 73/1000\n",
            "246/246 [==============================] - 3s 11ms/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.5291 - val_accuracy: 0.7805\n",
            "Epoch 74/1000\n",
            "246/246 [==============================] - 2s 10ms/step - loss: 0.4236 - accuracy: 0.7841 - val_loss: 0.5123 - val_accuracy: 0.7642\n",
            "Epoch 75/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.7760 - val_loss: 0.5168 - val_accuracy: 0.7480\n",
            "Epoch 76/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4316 - accuracy: 0.7800 - val_loss: 0.5112 - val_accuracy: 0.7805\n",
            "Epoch 77/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4211 - accuracy: 0.8024 - val_loss: 0.5382 - val_accuracy: 0.7886\n",
            "Epoch 78/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.8004 - val_loss: 0.5349 - val_accuracy: 0.7642\n",
            "Epoch 79/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4276 - accuracy: 0.7943 - val_loss: 0.5060 - val_accuracy: 0.8130\n",
            "Epoch 80/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4318 - accuracy: 0.7800 - val_loss: 0.5104 - val_accuracy: 0.7886\n",
            "Epoch 81/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.7841 - val_loss: 0.5180 - val_accuracy: 0.7724\n",
            "Epoch 82/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4248 - accuracy: 0.7943 - val_loss: 0.5180 - val_accuracy: 0.7561\n",
            "Epoch 83/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4307 - accuracy: 0.7780 - val_loss: 0.5158 - val_accuracy: 0.7805\n",
            "Epoch 84/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4253 - accuracy: 0.7658 - val_loss: 0.5349 - val_accuracy: 0.7805\n",
            "Epoch 85/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4250 - accuracy: 0.7984 - val_loss: 0.5702 - val_accuracy: 0.7805\n",
            "Epoch 86/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.8126 - val_loss: 0.5136 - val_accuracy: 0.7967\n",
            "Epoch 87/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4140 - accuracy: 0.8045 - val_loss: 0.5535 - val_accuracy: 0.7398\n",
            "Epoch 88/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4261 - accuracy: 0.7902 - val_loss: 0.5227 - val_accuracy: 0.7724\n",
            "Epoch 89/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4135 - accuracy: 0.8126 - val_loss: 0.5209 - val_accuracy: 0.7805\n",
            "Epoch 90/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4037 - accuracy: 0.7984 - val_loss: 0.5629 - val_accuracy: 0.7398\n",
            "Epoch 91/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4098 - accuracy: 0.8045 - val_loss: 0.5313 - val_accuracy: 0.7561\n",
            "Epoch 92/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4218 - accuracy: 0.7984 - val_loss: 0.5608 - val_accuracy: 0.7642\n",
            "Epoch 93/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4126 - accuracy: 0.7943 - val_loss: 0.5620 - val_accuracy: 0.7642\n",
            "Epoch 94/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4233 - accuracy: 0.7862 - val_loss: 0.5191 - val_accuracy: 0.7642\n",
            "Epoch 95/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4020 - accuracy: 0.8167 - val_loss: 0.5358 - val_accuracy: 0.7561\n",
            "Epoch 96/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.7963 - val_loss: 0.5243 - val_accuracy: 0.7886\n",
            "Epoch 97/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8004 - val_loss: 0.5605 - val_accuracy: 0.7724\n",
            "Epoch 98/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.4164 - accuracy: 0.8086 - val_loss: 0.5447 - val_accuracy: 0.7561\n",
            "Epoch 99/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3929 - accuracy: 0.8126 - val_loss: 0.5584 - val_accuracy: 0.7480\n",
            "Epoch 100/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.7923 - val_loss: 0.5488 - val_accuracy: 0.7561\n",
            "Epoch 101/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8126 - val_loss: 0.5306 - val_accuracy: 0.7967\n",
            "Epoch 102/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8065 - val_loss: 0.5468 - val_accuracy: 0.7724\n",
            "Epoch 103/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8065 - val_loss: 0.5246 - val_accuracy: 0.7886\n",
            "Epoch 104/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4098 - accuracy: 0.8045 - val_loss: 0.5371 - val_accuracy: 0.7724\n",
            "Epoch 105/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3963 - accuracy: 0.8289 - val_loss: 0.5673 - val_accuracy: 0.7398\n",
            "Epoch 106/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3939 - accuracy: 0.8045 - val_loss: 0.5407 - val_accuracy: 0.7317\n",
            "Epoch 107/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3955 - accuracy: 0.8086 - val_loss: 0.5503 - val_accuracy: 0.7642\n",
            "Epoch 108/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4022 - accuracy: 0.8065 - val_loss: 0.5505 - val_accuracy: 0.7724\n",
            "Epoch 109/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4052 - accuracy: 0.7963 - val_loss: 0.6555 - val_accuracy: 0.7317\n",
            "Epoch 110/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3919 - accuracy: 0.7984 - val_loss: 0.5636 - val_accuracy: 0.7642\n",
            "Epoch 111/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3975 - accuracy: 0.8187 - val_loss: 0.5642 - val_accuracy: 0.7561\n",
            "Epoch 112/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.4082 - accuracy: 0.7923 - val_loss: 0.5218 - val_accuracy: 0.7724\n",
            "Epoch 113/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3911 - accuracy: 0.8045 - val_loss: 0.5237 - val_accuracy: 0.7805\n",
            "Epoch 114/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3959 - accuracy: 0.8167 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 115/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8106 - val_loss: 0.5489 - val_accuracy: 0.7480\n",
            "Epoch 116/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.8147 - val_loss: 0.5246 - val_accuracy: 0.7724\n",
            "Epoch 117/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3950 - accuracy: 0.8126 - val_loss: 0.5514 - val_accuracy: 0.7561\n",
            "Epoch 118/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3937 - accuracy: 0.8187 - val_loss: 0.5424 - val_accuracy: 0.7561\n",
            "Epoch 119/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3964 - accuracy: 0.8004 - val_loss: 0.5225 - val_accuracy: 0.7805\n",
            "Epoch 120/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3992 - accuracy: 0.8065 - val_loss: 0.5434 - val_accuracy: 0.7724\n",
            "Epoch 121/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3881 - accuracy: 0.8065 - val_loss: 0.5272 - val_accuracy: 0.7886\n",
            "Epoch 122/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3913 - accuracy: 0.8004 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 123/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3860 - accuracy: 0.8086 - val_loss: 0.5431 - val_accuracy: 0.7724\n",
            "Epoch 124/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3993 - accuracy: 0.7902 - val_loss: 0.5597 - val_accuracy: 0.7317\n",
            "Epoch 125/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3874 - accuracy: 0.8208 - val_loss: 0.5305 - val_accuracy: 0.7805\n",
            "Epoch 126/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3800 - accuracy: 0.8167 - val_loss: 0.5390 - val_accuracy: 0.7642\n",
            "Epoch 127/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3800 - accuracy: 0.8330 - val_loss: 0.5783 - val_accuracy: 0.7805\n",
            "Epoch 128/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3836 - accuracy: 0.8126 - val_loss: 0.5661 - val_accuracy: 0.7398\n",
            "Epoch 129/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3856 - accuracy: 0.8208 - val_loss: 0.5573 - val_accuracy: 0.7642\n",
            "Epoch 130/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3917 - accuracy: 0.8248 - val_loss: 0.5468 - val_accuracy: 0.7724\n",
            "Epoch 131/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3866 - accuracy: 0.8167 - val_loss: 0.5438 - val_accuracy: 0.7724\n",
            "Epoch 132/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3841 - accuracy: 0.8126 - val_loss: 0.5369 - val_accuracy: 0.7642\n",
            "Epoch 133/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3815 - accuracy: 0.8167 - val_loss: 0.5652 - val_accuracy: 0.7724\n",
            "Epoch 134/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3728 - accuracy: 0.8289 - val_loss: 0.5423 - val_accuracy: 0.7642\n",
            "Epoch 135/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3819 - accuracy: 0.8045 - val_loss: 0.5491 - val_accuracy: 0.7480\n",
            "Epoch 136/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3800 - accuracy: 0.8065 - val_loss: 0.6196 - val_accuracy: 0.7317\n",
            "Epoch 137/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3848 - accuracy: 0.8065 - val_loss: 0.5560 - val_accuracy: 0.7724\n",
            "Epoch 138/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3914 - accuracy: 0.8126 - val_loss: 0.5374 - val_accuracy: 0.7642\n",
            "Epoch 139/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3825 - accuracy: 0.8330 - val_loss: 0.5702 - val_accuracy: 0.7317\n",
            "Epoch 140/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3782 - accuracy: 0.8167 - val_loss: 0.5640 - val_accuracy: 0.7480\n",
            "Epoch 141/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8208 - val_loss: 0.5685 - val_accuracy: 0.7561\n",
            "Epoch 142/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3844 - accuracy: 0.8432 - val_loss: 0.5648 - val_accuracy: 0.7317\n",
            "Epoch 143/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3670 - accuracy: 0.8248 - val_loss: 0.5575 - val_accuracy: 0.7805\n",
            "Epoch 144/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3796 - accuracy: 0.8147 - val_loss: 0.5961 - val_accuracy: 0.7398\n",
            "Epoch 145/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3741 - accuracy: 0.8147 - val_loss: 0.5473 - val_accuracy: 0.7480\n",
            "Epoch 146/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3874 - accuracy: 0.8310 - val_loss: 0.5838 - val_accuracy: 0.7480\n",
            "Epoch 147/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3804 - accuracy: 0.8065 - val_loss: 0.5178 - val_accuracy: 0.7967\n",
            "Epoch 148/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3731 - accuracy: 0.8147 - val_loss: 0.5704 - val_accuracy: 0.7805\n",
            "Epoch 149/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3675 - accuracy: 0.8126 - val_loss: 0.5460 - val_accuracy: 0.7724\n",
            "Epoch 150/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3731 - accuracy: 0.8350 - val_loss: 0.5129 - val_accuracy: 0.7967\n",
            "Epoch 151/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8187 - val_loss: 0.5706 - val_accuracy: 0.7236\n",
            "Epoch 152/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3829 - accuracy: 0.8248 - val_loss: 0.5662 - val_accuracy: 0.7398\n",
            "Epoch 153/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3697 - accuracy: 0.8086 - val_loss: 0.5360 - val_accuracy: 0.7967\n",
            "Epoch 154/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3688 - accuracy: 0.8391 - val_loss: 0.5365 - val_accuracy: 0.7561\n",
            "Epoch 155/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3705 - accuracy: 0.8167 - val_loss: 0.5464 - val_accuracy: 0.7642\n",
            "Epoch 156/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3635 - accuracy: 0.8269 - val_loss: 0.5459 - val_accuracy: 0.7805\n",
            "Epoch 157/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3626 - accuracy: 0.8208 - val_loss: 0.5565 - val_accuracy: 0.7480\n",
            "Epoch 158/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3637 - accuracy: 0.8411 - val_loss: 0.5653 - val_accuracy: 0.7561\n",
            "Epoch 159/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3599 - accuracy: 0.8208 - val_loss: 0.6057 - val_accuracy: 0.7317\n",
            "Epoch 160/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3634 - accuracy: 0.8187 - val_loss: 0.5618 - val_accuracy: 0.7398\n",
            "Epoch 161/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3664 - accuracy: 0.8289 - val_loss: 0.6342 - val_accuracy: 0.7398\n",
            "Epoch 162/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3652 - accuracy: 0.8228 - val_loss: 0.5957 - val_accuracy: 0.7805\n",
            "Epoch 163/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3751 - accuracy: 0.8187 - val_loss: 0.5796 - val_accuracy: 0.7154\n",
            "Epoch 164/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8208 - val_loss: 0.5489 - val_accuracy: 0.7967\n",
            "Epoch 165/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8208 - val_loss: 0.5286 - val_accuracy: 0.7724\n",
            "Epoch 166/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3525 - accuracy: 0.8330 - val_loss: 0.5809 - val_accuracy: 0.7236\n",
            "Epoch 167/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3719 - accuracy: 0.8350 - val_loss: 0.5649 - val_accuracy: 0.7236\n",
            "Epoch 168/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3578 - accuracy: 0.8473 - val_loss: 0.5732 - val_accuracy: 0.7886\n",
            "Epoch 169/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3666 - accuracy: 0.8208 - val_loss: 0.5738 - val_accuracy: 0.7805\n",
            "Epoch 170/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3584 - accuracy: 0.8045 - val_loss: 0.5721 - val_accuracy: 0.7886\n",
            "Epoch 171/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3597 - accuracy: 0.8187 - val_loss: 0.5666 - val_accuracy: 0.7561\n",
            "Epoch 172/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3637 - accuracy: 0.8411 - val_loss: 0.6058 - val_accuracy: 0.7724\n",
            "Epoch 173/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3572 - accuracy: 0.8187 - val_loss: 0.5591 - val_accuracy: 0.7480\n",
            "Epoch 174/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3532 - accuracy: 0.8310 - val_loss: 0.5814 - val_accuracy: 0.7073\n",
            "Epoch 175/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3615 - accuracy: 0.8167 - val_loss: 0.5589 - val_accuracy: 0.7236\n",
            "Epoch 176/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.3555 - accuracy: 0.8208 - val_loss: 0.5644 - val_accuracy: 0.7805\n",
            "Epoch 177/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3621 - accuracy: 0.8228 - val_loss: 0.5529 - val_accuracy: 0.7805\n",
            "Epoch 178/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3681 - accuracy: 0.8269 - val_loss: 0.5540 - val_accuracy: 0.7642\n",
            "Epoch 179/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3551 - accuracy: 0.8330 - val_loss: 0.5858 - val_accuracy: 0.7724\n",
            "Epoch 180/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3574 - accuracy: 0.8310 - val_loss: 0.5610 - val_accuracy: 0.7886\n",
            "Epoch 181/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3610 - accuracy: 0.8310 - val_loss: 0.5348 - val_accuracy: 0.7642\n",
            "Epoch 182/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3553 - accuracy: 0.8147 - val_loss: 0.5847 - val_accuracy: 0.7561\n",
            "Epoch 183/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3528 - accuracy: 0.8065 - val_loss: 0.5480 - val_accuracy: 0.7561\n",
            "Epoch 184/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3478 - accuracy: 0.8432 - val_loss: 0.5978 - val_accuracy: 0.7398\n",
            "Epoch 185/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3554 - accuracy: 0.8350 - val_loss: 0.5412 - val_accuracy: 0.7886\n",
            "Epoch 186/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3439 - accuracy: 0.8310 - val_loss: 0.5693 - val_accuracy: 0.7642\n",
            "Epoch 187/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3538 - accuracy: 0.8289 - val_loss: 0.5573 - val_accuracy: 0.7805\n",
            "Epoch 188/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3551 - accuracy: 0.8371 - val_loss: 0.5644 - val_accuracy: 0.7480\n",
            "Epoch 189/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3598 - accuracy: 0.8432 - val_loss: 0.5496 - val_accuracy: 0.7724\n",
            "Epoch 190/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3512 - accuracy: 0.8310 - val_loss: 0.5555 - val_accuracy: 0.7724\n",
            "Epoch 191/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3561 - accuracy: 0.8411 - val_loss: 0.6008 - val_accuracy: 0.7480\n",
            "Epoch 192/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8208 - val_loss: 0.5991 - val_accuracy: 0.7561\n",
            "Epoch 193/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3571 - accuracy: 0.8228 - val_loss: 0.5150 - val_accuracy: 0.7886\n",
            "Epoch 194/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3504 - accuracy: 0.8248 - val_loss: 0.5590 - val_accuracy: 0.7317\n",
            "Epoch 195/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3468 - accuracy: 0.8371 - val_loss: 0.5706 - val_accuracy: 0.7480\n",
            "Epoch 196/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3482 - accuracy: 0.8330 - val_loss: 0.5828 - val_accuracy: 0.7480\n",
            "Epoch 197/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3436 - accuracy: 0.8330 - val_loss: 0.5589 - val_accuracy: 0.7805\n",
            "Epoch 198/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3565 - accuracy: 0.8228 - val_loss: 0.5577 - val_accuracy: 0.7480\n",
            "Epoch 199/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8411 - val_loss: 0.6060 - val_accuracy: 0.7724\n",
            "Epoch 200/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3360 - accuracy: 0.8391 - val_loss: 0.8223 - val_accuracy: 0.6829\n",
            "Epoch 201/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3667 - accuracy: 0.8167 - val_loss: 0.5709 - val_accuracy: 0.7480\n",
            "Epoch 202/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3524 - accuracy: 0.8187 - val_loss: 0.5408 - val_accuracy: 0.7724\n",
            "Epoch 203/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3459 - accuracy: 0.8411 - val_loss: 0.6048 - val_accuracy: 0.7967\n",
            "Epoch 204/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3441 - accuracy: 0.8310 - val_loss: 0.5236 - val_accuracy: 0.7642\n",
            "Epoch 205/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3436 - accuracy: 0.8310 - val_loss: 0.5846 - val_accuracy: 0.7642\n",
            "Epoch 206/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3449 - accuracy: 0.8289 - val_loss: 0.6025 - val_accuracy: 0.7642\n",
            "Epoch 207/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3451 - accuracy: 0.8208 - val_loss: 0.5483 - val_accuracy: 0.7805\n",
            "Epoch 208/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3502 - accuracy: 0.8330 - val_loss: 0.5443 - val_accuracy: 0.7480\n",
            "Epoch 209/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3373 - accuracy: 0.8350 - val_loss: 0.5666 - val_accuracy: 0.7317\n",
            "Epoch 210/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3634 - accuracy: 0.8330 - val_loss: 0.6030 - val_accuracy: 0.7154\n",
            "Epoch 211/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.8330 - val_loss: 0.6504 - val_accuracy: 0.7317\n",
            "Epoch 212/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3447 - accuracy: 0.8452 - val_loss: 0.6074 - val_accuracy: 0.7561\n",
            "Epoch 213/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3382 - accuracy: 0.8371 - val_loss: 0.5813 - val_accuracy: 0.7561\n",
            "Epoch 214/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3430 - accuracy: 0.8330 - val_loss: 0.5345 - val_accuracy: 0.7317\n",
            "Epoch 215/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3430 - accuracy: 0.8391 - val_loss: 0.6338 - val_accuracy: 0.7642\n",
            "Epoch 216/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3539 - accuracy: 0.8452 - val_loss: 0.5266 - val_accuracy: 0.7561\n",
            "Epoch 217/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3365 - accuracy: 0.8411 - val_loss: 0.6443 - val_accuracy: 0.7317\n",
            "Epoch 218/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8513 - val_loss: 0.5681 - val_accuracy: 0.7642\n",
            "Epoch 219/1000\n",
            "246/246 [==============================] - 1s 4ms/step - loss: 0.3283 - accuracy: 0.8513 - val_loss: 0.6730 - val_accuracy: 0.7236\n",
            "Epoch 220/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3339 - accuracy: 0.8411 - val_loss: 0.6082 - val_accuracy: 0.7398\n",
            "Epoch 221/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3279 - accuracy: 0.8534 - val_loss: 0.5947 - val_accuracy: 0.7724\n",
            "Epoch 222/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3278 - accuracy: 0.8493 - val_loss: 0.5516 - val_accuracy: 0.7724\n",
            "Epoch 223/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3392 - accuracy: 0.8371 - val_loss: 0.5515 - val_accuracy: 0.7805\n",
            "Epoch 224/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3225 - accuracy: 0.8473 - val_loss: 0.6196 - val_accuracy: 0.7724\n",
            "Epoch 225/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3201 - accuracy: 0.8432 - val_loss: 0.6220 - val_accuracy: 0.7398\n",
            "Epoch 226/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8330 - val_loss: 0.5382 - val_accuracy: 0.7561\n",
            "Epoch 227/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3396 - accuracy: 0.8432 - val_loss: 0.6036 - val_accuracy: 0.7642\n",
            "Epoch 228/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3273 - accuracy: 0.8391 - val_loss: 0.6675 - val_accuracy: 0.7642\n",
            "Epoch 229/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3174 - accuracy: 0.8473 - val_loss: 0.5993 - val_accuracy: 0.7805\n",
            "Epoch 230/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3297 - accuracy: 0.8411 - val_loss: 0.6272 - val_accuracy: 0.7317\n",
            "Epoch 231/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3217 - accuracy: 0.8411 - val_loss: 0.6292 - val_accuracy: 0.7398\n",
            "Epoch 232/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3336 - accuracy: 0.8330 - val_loss: 0.6202 - val_accuracy: 0.7236\n",
            "Epoch 233/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3349 - accuracy: 0.8534 - val_loss: 0.6318 - val_accuracy: 0.7398\n",
            "Epoch 234/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8574 - val_loss: 0.6034 - val_accuracy: 0.7724\n",
            "Epoch 235/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3168 - accuracy: 0.8534 - val_loss: 0.5833 - val_accuracy: 0.7561\n",
            "Epoch 236/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.8310 - val_loss: 0.6964 - val_accuracy: 0.7317\n",
            "Epoch 237/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3378 - accuracy: 0.8473 - val_loss: 0.6053 - val_accuracy: 0.7561\n",
            "Epoch 238/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3317 - accuracy: 0.8452 - val_loss: 0.6574 - val_accuracy: 0.7154\n",
            "Epoch 239/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3153 - accuracy: 0.8391 - val_loss: 0.6117 - val_accuracy: 0.7561\n",
            "Epoch 240/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3402 - accuracy: 0.8452 - val_loss: 0.6012 - val_accuracy: 0.7480\n",
            "Epoch 241/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3289 - accuracy: 0.8350 - val_loss: 0.5693 - val_accuracy: 0.7398\n",
            "Epoch 242/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3193 - accuracy: 0.8432 - val_loss: 0.6387 - val_accuracy: 0.7724\n",
            "Epoch 243/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3265 - accuracy: 0.8391 - val_loss: 0.5870 - val_accuracy: 0.7561\n",
            "Epoch 244/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3202 - accuracy: 0.8473 - val_loss: 0.6300 - val_accuracy: 0.7236\n",
            "Epoch 245/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3196 - accuracy: 0.8473 - val_loss: 0.5746 - val_accuracy: 0.7317\n",
            "Epoch 246/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3203 - accuracy: 0.8350 - val_loss: 0.5762 - val_accuracy: 0.7317\n",
            "Epoch 247/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3188 - accuracy: 0.8513 - val_loss: 0.7401 - val_accuracy: 0.7236\n",
            "Epoch 248/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3362 - accuracy: 0.8350 - val_loss: 0.6000 - val_accuracy: 0.7480\n",
            "Epoch 249/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3094 - accuracy: 0.8513 - val_loss: 0.8111 - val_accuracy: 0.7073\n",
            "Epoch 250/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3295 - accuracy: 0.8371 - val_loss: 0.6429 - val_accuracy: 0.7642\n",
            "Epoch 251/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3235 - accuracy: 0.8452 - val_loss: 0.5454 - val_accuracy: 0.7480\n",
            "Epoch 252/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3160 - accuracy: 0.8371 - val_loss: 0.6265 - val_accuracy: 0.7642\n",
            "Epoch 253/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3229 - accuracy: 0.8473 - val_loss: 0.5738 - val_accuracy: 0.7480\n",
            "Epoch 254/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3251 - accuracy: 0.8493 - val_loss: 0.5458 - val_accuracy: 0.7398\n",
            "Epoch 255/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3117 - accuracy: 0.8574 - val_loss: 0.6664 - val_accuracy: 0.6829\n",
            "Epoch 256/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3023 - accuracy: 0.8411 - val_loss: 0.6699 - val_accuracy: 0.7317\n",
            "Epoch 257/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3191 - accuracy: 0.8635 - val_loss: 0.6454 - val_accuracy: 0.7073\n",
            "Epoch 258/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3041 - accuracy: 0.8473 - val_loss: 0.5482 - val_accuracy: 0.7236\n",
            "Epoch 259/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3139 - accuracy: 0.8452 - val_loss: 0.5709 - val_accuracy: 0.7398\n",
            "Epoch 260/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.3085 - accuracy: 0.8452 - val_loss: 0.7235 - val_accuracy: 0.7236\n",
            "Epoch 261/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3091 - accuracy: 0.8411 - val_loss: 0.5986 - val_accuracy: 0.7561\n",
            "Epoch 262/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2959 - accuracy: 0.8595 - val_loss: 0.6211 - val_accuracy: 0.7236\n",
            "Epoch 263/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3215 - accuracy: 0.8473 - val_loss: 0.5832 - val_accuracy: 0.7154\n",
            "Epoch 264/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3259 - accuracy: 0.8432 - val_loss: 0.6336 - val_accuracy: 0.7236\n",
            "Epoch 265/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3103 - accuracy: 0.8554 - val_loss: 0.6241 - val_accuracy: 0.7480\n",
            "Epoch 266/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2894 - accuracy: 0.8615 - val_loss: 0.7812 - val_accuracy: 0.6667\n",
            "Epoch 267/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3062 - accuracy: 0.8411 - val_loss: 0.6327 - val_accuracy: 0.7561\n",
            "Epoch 268/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2975 - accuracy: 0.8473 - val_loss: 0.7451 - val_accuracy: 0.6992\n",
            "Epoch 269/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3035 - accuracy: 0.8635 - val_loss: 0.6653 - val_accuracy: 0.7317\n",
            "Epoch 270/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3058 - accuracy: 0.8432 - val_loss: 0.6402 - val_accuracy: 0.7561\n",
            "Epoch 271/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3038 - accuracy: 0.8411 - val_loss: 0.6900 - val_accuracy: 0.7398\n",
            "Epoch 272/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3288 - accuracy: 0.8432 - val_loss: 0.6126 - val_accuracy: 0.7398\n",
            "Epoch 273/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2766 - accuracy: 0.8798 - val_loss: 0.7516 - val_accuracy: 0.7236\n",
            "Epoch 274/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2998 - accuracy: 0.8513 - val_loss: 0.6230 - val_accuracy: 0.7154\n",
            "Epoch 275/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3177 - accuracy: 0.8473 - val_loss: 0.6260 - val_accuracy: 0.7480\n",
            "Epoch 276/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3016 - accuracy: 0.8615 - val_loss: 0.6344 - val_accuracy: 0.7561\n",
            "Epoch 277/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3247 - accuracy: 0.8432 - val_loss: 0.6672 - val_accuracy: 0.7561\n",
            "Epoch 278/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3071 - accuracy: 0.8595 - val_loss: 0.6610 - val_accuracy: 0.7398\n",
            "Epoch 279/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.8635 - val_loss: 0.7243 - val_accuracy: 0.7073\n",
            "Epoch 280/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.8697 - val_loss: 0.6771 - val_accuracy: 0.7317\n",
            "Epoch 281/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2798 - accuracy: 0.8635 - val_loss: 0.6269 - val_accuracy: 0.7154\n",
            "Epoch 282/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2975 - accuracy: 0.8635 - val_loss: 0.6484 - val_accuracy: 0.7642\n",
            "Epoch 283/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2974 - accuracy: 0.8554 - val_loss: 0.6843 - val_accuracy: 0.7561\n",
            "Epoch 284/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3085 - accuracy: 0.8656 - val_loss: 0.6053 - val_accuracy: 0.7154\n",
            "Epoch 285/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3009 - accuracy: 0.8473 - val_loss: 0.6396 - val_accuracy: 0.7561\n",
            "Epoch 286/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2807 - accuracy: 0.8737 - val_loss: 0.6540 - val_accuracy: 0.7480\n",
            "Epoch 287/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2924 - accuracy: 0.8778 - val_loss: 0.6520 - val_accuracy: 0.6829\n",
            "Epoch 288/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2884 - accuracy: 0.8534 - val_loss: 0.7395 - val_accuracy: 0.6667\n",
            "Epoch 289/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2989 - accuracy: 0.8697 - val_loss: 0.7057 - val_accuracy: 0.6748\n",
            "Epoch 290/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2841 - accuracy: 0.8717 - val_loss: 0.8220 - val_accuracy: 0.6992\n",
            "Epoch 291/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2896 - accuracy: 0.8676 - val_loss: 0.7792 - val_accuracy: 0.7317\n",
            "Epoch 292/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2851 - accuracy: 0.8574 - val_loss: 0.7854 - val_accuracy: 0.6829\n",
            "Epoch 293/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2896 - accuracy: 0.8717 - val_loss: 0.6819 - val_accuracy: 0.7398\n",
            "Epoch 294/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2715 - accuracy: 0.8778 - val_loss: 0.6799 - val_accuracy: 0.7480\n",
            "Epoch 295/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2874 - accuracy: 0.8554 - val_loss: 0.6903 - val_accuracy: 0.7398\n",
            "Epoch 296/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2936 - accuracy: 0.8635 - val_loss: 0.7214 - val_accuracy: 0.7317\n",
            "Epoch 297/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2836 - accuracy: 0.8737 - val_loss: 0.6661 - val_accuracy: 0.7561\n",
            "Epoch 298/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2727 - accuracy: 0.8737 - val_loss: 0.8032 - val_accuracy: 0.7236\n",
            "Epoch 299/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2828 - accuracy: 0.8676 - val_loss: 0.6723 - val_accuracy: 0.7154\n",
            "Epoch 300/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2806 - accuracy: 0.8798 - val_loss: 0.7151 - val_accuracy: 0.7561\n",
            "Epoch 301/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2685 - accuracy: 0.8798 - val_loss: 0.7174 - val_accuracy: 0.7154\n",
            "Epoch 302/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2800 - accuracy: 0.8676 - val_loss: 0.7923 - val_accuracy: 0.6829\n",
            "Epoch 303/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2883 - accuracy: 0.8778 - val_loss: 0.6960 - val_accuracy: 0.6748\n",
            "Epoch 304/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2654 - accuracy: 0.8758 - val_loss: 0.7816 - val_accuracy: 0.7561\n",
            "Epoch 305/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2808 - accuracy: 0.8798 - val_loss: 0.7042 - val_accuracy: 0.7642\n",
            "Epoch 306/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2910 - accuracy: 0.8534 - val_loss: 0.7584 - val_accuracy: 0.7073\n",
            "Epoch 307/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2730 - accuracy: 0.8758 - val_loss: 0.7329 - val_accuracy: 0.7154\n",
            "Epoch 308/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2804 - accuracy: 0.8656 - val_loss: 0.6856 - val_accuracy: 0.7073\n",
            "Epoch 309/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2762 - accuracy: 0.8635 - val_loss: 0.7713 - val_accuracy: 0.7317\n",
            "Epoch 310/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2787 - accuracy: 0.8819 - val_loss: 0.7789 - val_accuracy: 0.7154\n",
            "Epoch 311/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2635 - accuracy: 0.8921 - val_loss: 0.7862 - val_accuracy: 0.7398\n",
            "Epoch 312/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2737 - accuracy: 0.8737 - val_loss: 0.6646 - val_accuracy: 0.6748\n",
            "Epoch 313/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2884 - accuracy: 0.8574 - val_loss: 0.6880 - val_accuracy: 0.7073\n",
            "Epoch 314/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2789 - accuracy: 0.8676 - val_loss: 0.6584 - val_accuracy: 0.7398\n",
            "Epoch 315/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2881 - accuracy: 0.8635 - val_loss: 0.6637 - val_accuracy: 0.7317\n",
            "Epoch 316/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2769 - accuracy: 0.8717 - val_loss: 0.7432 - val_accuracy: 0.7236\n",
            "Epoch 317/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2753 - accuracy: 0.8717 - val_loss: 0.7900 - val_accuracy: 0.6911\n",
            "Epoch 318/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2677 - accuracy: 0.8921 - val_loss: 0.8056 - val_accuracy: 0.6667\n",
            "Epoch 319/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2865 - accuracy: 0.8554 - val_loss: 0.7251 - val_accuracy: 0.7317\n",
            "Epoch 320/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2557 - accuracy: 0.8880 - val_loss: 0.6651 - val_accuracy: 0.7398\n",
            "Epoch 321/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2680 - accuracy: 0.8961 - val_loss: 0.7135 - val_accuracy: 0.7154\n",
            "Epoch 322/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2575 - accuracy: 0.8798 - val_loss: 0.7991 - val_accuracy: 0.6992\n",
            "Epoch 323/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3016 - accuracy: 0.8676 - val_loss: 0.7398 - val_accuracy: 0.7154\n",
            "Epoch 324/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2534 - accuracy: 0.8900 - val_loss: 0.6430 - val_accuracy: 0.7642\n",
            "Epoch 325/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2568 - accuracy: 0.8839 - val_loss: 0.7411 - val_accuracy: 0.6829\n",
            "Epoch 326/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2936 - accuracy: 0.8574 - val_loss: 0.6678 - val_accuracy: 0.7398\n",
            "Epoch 327/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2830 - accuracy: 0.8554 - val_loss: 0.7340 - val_accuracy: 0.6992\n",
            "Epoch 328/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2510 - accuracy: 0.8900 - val_loss: 0.7533 - val_accuracy: 0.7398\n",
            "Epoch 329/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2495 - accuracy: 0.8839 - val_loss: 0.7322 - val_accuracy: 0.7317\n",
            "Epoch 330/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2524 - accuracy: 0.8880 - val_loss: 0.7479 - val_accuracy: 0.7317\n",
            "Epoch 331/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2463 - accuracy: 0.8982 - val_loss: 0.8242 - val_accuracy: 0.7480\n",
            "Epoch 332/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2639 - accuracy: 0.8900 - val_loss: 0.6836 - val_accuracy: 0.7154\n",
            "Epoch 333/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2465 - accuracy: 0.8859 - val_loss: 0.7379 - val_accuracy: 0.7480\n",
            "Epoch 334/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2374 - accuracy: 0.8880 - val_loss: 0.7788 - val_accuracy: 0.7398\n",
            "Epoch 335/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2640 - accuracy: 0.8859 - val_loss: 0.6610 - val_accuracy: 0.7154\n",
            "Epoch 336/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2406 - accuracy: 0.9002 - val_loss: 0.8698 - val_accuracy: 0.6829\n",
            "Epoch 337/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2839 - accuracy: 0.8656 - val_loss: 0.7780 - val_accuracy: 0.7073\n",
            "Epoch 338/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2667 - accuracy: 0.8839 - val_loss: 0.7122 - val_accuracy: 0.7317\n",
            "Epoch 339/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2465 - accuracy: 0.8961 - val_loss: 0.8963 - val_accuracy: 0.6748\n",
            "Epoch 340/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2534 - accuracy: 0.8819 - val_loss: 0.7088 - val_accuracy: 0.7480\n",
            "Epoch 341/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2416 - accuracy: 0.8859 - val_loss: 0.7761 - val_accuracy: 0.7236\n",
            "Epoch 342/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2413 - accuracy: 0.8961 - val_loss: 0.8385 - val_accuracy: 0.7154\n",
            "Epoch 343/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2456 - accuracy: 0.8941 - val_loss: 0.8016 - val_accuracy: 0.7073\n",
            "Epoch 344/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2713 - accuracy: 0.8778 - val_loss: 0.9777 - val_accuracy: 0.6667\n",
            "Epoch 345/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2727 - accuracy: 0.8859 - val_loss: 0.7411 - val_accuracy: 0.7317\n",
            "Epoch 346/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2553 - accuracy: 0.8961 - val_loss: 0.7357 - val_accuracy: 0.6667\n",
            "Epoch 347/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2236 - accuracy: 0.9145 - val_loss: 0.8372 - val_accuracy: 0.7317\n",
            "Epoch 348/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2513 - accuracy: 0.8859 - val_loss: 0.8521 - val_accuracy: 0.6992\n",
            "Epoch 349/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2672 - accuracy: 0.8839 - val_loss: 0.8107 - val_accuracy: 0.7073\n",
            "Epoch 350/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2423 - accuracy: 0.9002 - val_loss: 0.8366 - val_accuracy: 0.7236\n",
            "Epoch 351/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2269 - accuracy: 0.9104 - val_loss: 0.8914 - val_accuracy: 0.7236\n",
            "Epoch 352/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2466 - accuracy: 0.8921 - val_loss: 0.8670 - val_accuracy: 0.7317\n",
            "Epoch 353/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2347 - accuracy: 0.9043 - val_loss: 0.8571 - val_accuracy: 0.7398\n",
            "Epoch 354/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2682 - accuracy: 0.8737 - val_loss: 0.7804 - val_accuracy: 0.7317\n",
            "Epoch 355/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2461 - accuracy: 0.8921 - val_loss: 0.8055 - val_accuracy: 0.7317\n",
            "Epoch 356/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2221 - accuracy: 0.9002 - val_loss: 0.8623 - val_accuracy: 0.7317\n",
            "Epoch 357/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2416 - accuracy: 0.8982 - val_loss: 0.7973 - val_accuracy: 0.7317\n",
            "Epoch 358/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2443 - accuracy: 0.9043 - val_loss: 0.7834 - val_accuracy: 0.7480\n",
            "Epoch 359/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2570 - accuracy: 0.8839 - val_loss: 1.0116 - val_accuracy: 0.6829\n",
            "Epoch 360/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2267 - accuracy: 0.8921 - val_loss: 0.9299 - val_accuracy: 0.7154\n",
            "Epoch 361/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2211 - accuracy: 0.9124 - val_loss: 0.8631 - val_accuracy: 0.7073\n",
            "Epoch 362/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2486 - accuracy: 0.8941 - val_loss: 0.7329 - val_accuracy: 0.7561\n",
            "Epoch 363/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2298 - accuracy: 0.9022 - val_loss: 0.7964 - val_accuracy: 0.7398\n",
            "Epoch 364/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2224 - accuracy: 0.9002 - val_loss: 0.8427 - val_accuracy: 0.7236\n",
            "Epoch 365/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2599 - accuracy: 0.8921 - val_loss: 0.7610 - val_accuracy: 0.7154\n",
            "Epoch 366/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9002 - val_loss: 0.8196 - val_accuracy: 0.7236\n",
            "Epoch 367/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2298 - accuracy: 0.9145 - val_loss: 0.8049 - val_accuracy: 0.7236\n",
            "Epoch 368/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2257 - accuracy: 0.9063 - val_loss: 0.8111 - val_accuracy: 0.7561\n",
            "Epoch 369/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2401 - accuracy: 0.8880 - val_loss: 0.8063 - val_accuracy: 0.7642\n",
            "Epoch 370/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1891 - accuracy: 0.9287 - val_loss: 0.8277 - val_accuracy: 0.7480\n",
            "Epoch 371/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2418 - accuracy: 0.9002 - val_loss: 0.7962 - val_accuracy: 0.7154\n",
            "Epoch 372/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2614 - accuracy: 0.8778 - val_loss: 0.7596 - val_accuracy: 0.7317\n",
            "Epoch 373/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2032 - accuracy: 0.9022 - val_loss: 0.9049 - val_accuracy: 0.7398\n",
            "Epoch 374/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2563 - accuracy: 0.8819 - val_loss: 0.7471 - val_accuracy: 0.7236\n",
            "Epoch 375/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2263 - accuracy: 0.8839 - val_loss: 0.8430 - val_accuracy: 0.6992\n",
            "Epoch 376/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2175 - accuracy: 0.8941 - val_loss: 0.9105 - val_accuracy: 0.7073\n",
            "Epoch 377/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2091 - accuracy: 0.9124 - val_loss: 0.7956 - val_accuracy: 0.6911\n",
            "Epoch 378/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2614 - accuracy: 0.8737 - val_loss: 0.9718 - val_accuracy: 0.6829\n",
            "Epoch 379/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2808 - accuracy: 0.8798 - val_loss: 0.8357 - val_accuracy: 0.7236\n",
            "Epoch 380/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2552 - accuracy: 0.8737 - val_loss: 0.6897 - val_accuracy: 0.7561\n",
            "Epoch 381/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2283 - accuracy: 0.8982 - val_loss: 0.8467 - val_accuracy: 0.7236\n",
            "Epoch 382/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2222 - accuracy: 0.8982 - val_loss: 0.8379 - val_accuracy: 0.7480\n",
            "Epoch 383/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2537 - accuracy: 0.8839 - val_loss: 0.8376 - val_accuracy: 0.7154\n",
            "Epoch 384/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2439 - accuracy: 0.8880 - val_loss: 0.8121 - val_accuracy: 0.7480\n",
            "Epoch 385/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2380 - accuracy: 0.8941 - val_loss: 0.7644 - val_accuracy: 0.7398\n",
            "Epoch 386/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2196 - accuracy: 0.9185 - val_loss: 0.8115 - val_accuracy: 0.7317\n",
            "Epoch 387/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2151 - accuracy: 0.9063 - val_loss: 0.8101 - val_accuracy: 0.7236\n",
            "Epoch 388/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2299 - accuracy: 0.8982 - val_loss: 0.8439 - val_accuracy: 0.7154\n",
            "Epoch 389/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9206 - val_loss: 0.7834 - val_accuracy: 0.7480\n",
            "Epoch 390/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2017 - accuracy: 0.9124 - val_loss: 0.9541 - val_accuracy: 0.6667\n",
            "Epoch 391/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2272 - accuracy: 0.9063 - val_loss: 0.8189 - val_accuracy: 0.7236\n",
            "Epoch 392/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1827 - accuracy: 0.9287 - val_loss: 0.9165 - val_accuracy: 0.7073\n",
            "Epoch 393/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1630 - accuracy: 0.9389 - val_loss: 0.9711 - val_accuracy: 0.6911\n",
            "Epoch 394/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2216 - accuracy: 0.9043 - val_loss: 1.0172 - val_accuracy: 0.6748\n",
            "Epoch 395/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2451 - accuracy: 0.8859 - val_loss: 0.8187 - val_accuracy: 0.7398\n",
            "Epoch 396/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1728 - accuracy: 0.9308 - val_loss: 0.8764 - val_accuracy: 0.7154\n",
            "Epoch 397/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1948 - accuracy: 0.9145 - val_loss: 0.8509 - val_accuracy: 0.7561\n",
            "Epoch 398/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2280 - accuracy: 0.9002 - val_loss: 0.8087 - val_accuracy: 0.7398\n",
            "Epoch 399/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1976 - accuracy: 0.9104 - val_loss: 0.9454 - val_accuracy: 0.6911\n",
            "Epoch 400/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2308 - accuracy: 0.9063 - val_loss: 0.8770 - val_accuracy: 0.7398\n",
            "Epoch 401/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2067 - accuracy: 0.9063 - val_loss: 0.8060 - val_accuracy: 0.6992\n",
            "Epoch 402/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2055 - accuracy: 0.8982 - val_loss: 0.8763 - val_accuracy: 0.7154\n",
            "Epoch 403/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1759 - accuracy: 0.9287 - val_loss: 0.9674 - val_accuracy: 0.7154\n",
            "Epoch 404/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2100 - accuracy: 0.8982 - val_loss: 0.8455 - val_accuracy: 0.7480\n",
            "Epoch 405/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2460 - accuracy: 0.8961 - val_loss: 0.8338 - val_accuracy: 0.7317\n",
            "Epoch 406/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1982 - accuracy: 0.9124 - val_loss: 0.9128 - val_accuracy: 0.6829\n",
            "Epoch 407/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3122 - accuracy: 0.8798 - val_loss: 0.7957 - val_accuracy: 0.7398\n",
            "Epoch 408/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1822 - accuracy: 0.9308 - val_loss: 0.8580 - val_accuracy: 0.7073\n",
            "Epoch 409/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1706 - accuracy: 0.9267 - val_loss: 0.8497 - val_accuracy: 0.7154\n",
            "Epoch 410/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2030 - accuracy: 0.9104 - val_loss: 0.8973 - val_accuracy: 0.7398\n",
            "Epoch 411/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1741 - accuracy: 0.9308 - val_loss: 1.1287 - val_accuracy: 0.6992\n",
            "Epoch 412/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2175 - accuracy: 0.9124 - val_loss: 0.8579 - val_accuracy: 0.7154\n",
            "Epoch 413/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1668 - accuracy: 0.9226 - val_loss: 0.9175 - val_accuracy: 0.7317\n",
            "Epoch 414/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2070 - accuracy: 0.9165 - val_loss: 0.8882 - val_accuracy: 0.7236\n",
            "Epoch 415/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2193 - accuracy: 0.9063 - val_loss: 0.8169 - val_accuracy: 0.7398\n",
            "Epoch 416/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1949 - accuracy: 0.9145 - val_loss: 0.8698 - val_accuracy: 0.7398\n",
            "Epoch 417/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1779 - accuracy: 0.9246 - val_loss: 1.0353 - val_accuracy: 0.6585\n",
            "Epoch 418/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2155 - accuracy: 0.9124 - val_loss: 0.8466 - val_accuracy: 0.7480\n",
            "Epoch 419/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1824 - accuracy: 0.9206 - val_loss: 0.9107 - val_accuracy: 0.7561\n",
            "Epoch 420/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1789 - accuracy: 0.9185 - val_loss: 0.8528 - val_accuracy: 0.7724\n",
            "Epoch 421/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1849 - accuracy: 0.9287 - val_loss: 0.9117 - val_accuracy: 0.7480\n",
            "Epoch 422/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1597 - accuracy: 0.9430 - val_loss: 0.8707 - val_accuracy: 0.7642\n",
            "Epoch 423/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1762 - accuracy: 0.9226 - val_loss: 0.9608 - val_accuracy: 0.7398\n",
            "Epoch 424/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1623 - accuracy: 0.9369 - val_loss: 1.0055 - val_accuracy: 0.6748\n",
            "Epoch 425/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1818 - accuracy: 0.9246 - val_loss: 0.8730 - val_accuracy: 0.7561\n",
            "Epoch 426/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2641 - accuracy: 0.8839 - val_loss: 0.7783 - val_accuracy: 0.6911\n",
            "Epoch 427/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1655 - accuracy: 0.9348 - val_loss: 0.8425 - val_accuracy: 0.7480\n",
            "Epoch 428/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1586 - accuracy: 0.9430 - val_loss: 0.8118 - val_accuracy: 0.7561\n",
            "Epoch 429/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1487 - accuracy: 0.9389 - val_loss: 0.8669 - val_accuracy: 0.6911\n",
            "Epoch 430/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2046 - accuracy: 0.9226 - val_loss: 0.7434 - val_accuracy: 0.7398\n",
            "Epoch 431/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1769 - accuracy: 0.9226 - val_loss: 0.9210 - val_accuracy: 0.7236\n",
            "Epoch 432/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2054 - accuracy: 0.8961 - val_loss: 1.4491 - val_accuracy: 0.6585\n",
            "Epoch 433/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3094 - accuracy: 0.8635 - val_loss: 0.8555 - val_accuracy: 0.7236\n",
            "Epoch 434/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2059 - accuracy: 0.9145 - val_loss: 0.8159 - val_accuracy: 0.7561\n",
            "Epoch 435/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1776 - accuracy: 0.9185 - val_loss: 0.8145 - val_accuracy: 0.7886\n",
            "Epoch 436/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1292 - accuracy: 0.9511 - val_loss: 0.8863 - val_accuracy: 0.7480\n",
            "Epoch 437/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1978 - accuracy: 0.9063 - val_loss: 0.9029 - val_accuracy: 0.7317\n",
            "Epoch 438/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1958 - accuracy: 0.9124 - val_loss: 0.8438 - val_accuracy: 0.7154\n",
            "Epoch 439/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1383 - accuracy: 0.9430 - val_loss: 0.9929 - val_accuracy: 0.7480\n",
            "Epoch 440/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2017 - accuracy: 0.9124 - val_loss: 0.9420 - val_accuracy: 0.6829\n",
            "Epoch 441/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1257 - accuracy: 0.9552 - val_loss: 1.0219 - val_accuracy: 0.6992\n",
            "Epoch 442/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2131 - accuracy: 0.9124 - val_loss: 0.9767 - val_accuracy: 0.7236\n",
            "Epoch 443/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1726 - accuracy: 0.9287 - val_loss: 0.9048 - val_accuracy: 0.7236\n",
            "Epoch 444/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1515 - accuracy: 0.9450 - val_loss: 0.8426 - val_accuracy: 0.7561\n",
            "Epoch 445/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2096 - accuracy: 0.9145 - val_loss: 1.0351 - val_accuracy: 0.6992\n",
            "Epoch 446/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1938 - accuracy: 0.9185 - val_loss: 0.9285 - val_accuracy: 0.7317\n",
            "Epoch 447/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1936 - accuracy: 0.9226 - val_loss: 0.9505 - val_accuracy: 0.7073\n",
            "Epoch 448/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1320 - accuracy: 0.9430 - val_loss: 0.9843 - val_accuracy: 0.7398\n",
            "Epoch 449/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2690 - accuracy: 0.8880 - val_loss: 0.8305 - val_accuracy: 0.7642\n",
            "Epoch 450/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2759 - accuracy: 0.8839 - val_loss: 0.7895 - val_accuracy: 0.7561\n",
            "Epoch 451/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1558 - accuracy: 0.9328 - val_loss: 0.9310 - val_accuracy: 0.6992\n",
            "Epoch 452/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1423 - accuracy: 0.9409 - val_loss: 1.0133 - val_accuracy: 0.7073\n",
            "Epoch 453/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1600 - accuracy: 0.9409 - val_loss: 0.8270 - val_accuracy: 0.7642\n",
            "Epoch 454/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1496 - accuracy: 0.9369 - val_loss: 0.8948 - val_accuracy: 0.7398\n",
            "Epoch 455/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1438 - accuracy: 0.9450 - val_loss: 0.8852 - val_accuracy: 0.7317\n",
            "Epoch 456/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1842 - accuracy: 0.9246 - val_loss: 0.8904 - val_accuracy: 0.7398\n",
            "Epoch 457/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1375 - accuracy: 0.9430 - val_loss: 0.8650 - val_accuracy: 0.7317\n",
            "Epoch 458/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1683 - accuracy: 0.9348 - val_loss: 0.9562 - val_accuracy: 0.7154\n",
            "Epoch 459/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1679 - accuracy: 0.9348 - val_loss: 0.9205 - val_accuracy: 0.7724\n",
            "Epoch 460/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1805 - accuracy: 0.9389 - val_loss: 1.0154 - val_accuracy: 0.7317\n",
            "Epoch 461/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1579 - accuracy: 0.9389 - val_loss: 0.9542 - val_accuracy: 0.7236\n",
            "Epoch 462/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1319 - accuracy: 0.9470 - val_loss: 1.0451 - val_accuracy: 0.6992\n",
            "Epoch 463/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1349 - accuracy: 0.9389 - val_loss: 0.9465 - val_accuracy: 0.7398\n",
            "Epoch 464/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9369 - val_loss: 1.2288 - val_accuracy: 0.6748\n",
            "Epoch 465/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1629 - accuracy: 0.9430 - val_loss: 0.9363 - val_accuracy: 0.7724\n",
            "Epoch 466/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9511 - val_loss: 1.1182 - val_accuracy: 0.7317\n",
            "Epoch 467/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3127 - accuracy: 0.8758 - val_loss: 0.8909 - val_accuracy: 0.7480\n",
            "Epoch 468/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1828 - accuracy: 0.9308 - val_loss: 0.9075 - val_accuracy: 0.6992\n",
            "Epoch 469/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0936 - accuracy: 0.9695 - val_loss: 0.9666 - val_accuracy: 0.7480\n",
            "Epoch 470/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1489 - accuracy: 0.9369 - val_loss: 0.9140 - val_accuracy: 0.7480\n",
            "Epoch 471/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1624 - accuracy: 0.9348 - val_loss: 0.9182 - val_accuracy: 0.7480\n",
            "Epoch 472/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9593 - val_loss: 1.0311 - val_accuracy: 0.7398\n",
            "Epoch 473/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1562 - accuracy: 0.9328 - val_loss: 1.0780 - val_accuracy: 0.7805\n",
            "Epoch 474/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1460 - accuracy: 0.9369 - val_loss: 1.0614 - val_accuracy: 0.7561\n",
            "Epoch 475/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0930 - accuracy: 0.9654 - val_loss: 1.1408 - val_accuracy: 0.7236\n",
            "Epoch 476/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1762 - accuracy: 0.9287 - val_loss: 1.0238 - val_accuracy: 0.7724\n",
            "Epoch 477/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1281 - accuracy: 0.9532 - val_loss: 1.2076 - val_accuracy: 0.7154\n",
            "Epoch 478/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2387 - accuracy: 0.9104 - val_loss: 1.0154 - val_accuracy: 0.7317\n",
            "Epoch 479/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1610 - accuracy: 0.9389 - val_loss: 0.9686 - val_accuracy: 0.7317\n",
            "Epoch 480/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0920 - accuracy: 0.9674 - val_loss: 0.9850 - val_accuracy: 0.7154\n",
            "Epoch 481/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9674 - val_loss: 1.0606 - val_accuracy: 0.7561\n",
            "Epoch 482/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1420 - accuracy: 0.9409 - val_loss: 1.0820 - val_accuracy: 0.6992\n",
            "Epoch 483/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1128 - accuracy: 0.9572 - val_loss: 1.0571 - val_accuracy: 0.7642\n",
            "Epoch 484/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1545 - accuracy: 0.9409 - val_loss: 1.0215 - val_accuracy: 0.7236\n",
            "Epoch 485/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2276 - accuracy: 0.9022 - val_loss: 1.0091 - val_accuracy: 0.7805\n",
            "Epoch 486/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1274 - accuracy: 0.9613 - val_loss: 1.0125 - val_accuracy: 0.7073\n",
            "Epoch 487/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1942 - accuracy: 0.9063 - val_loss: 0.9588 - val_accuracy: 0.7480\n",
            "Epoch 488/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1419 - accuracy: 0.9470 - val_loss: 0.8661 - val_accuracy: 0.7886\n",
            "Epoch 489/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1974 - accuracy: 0.9206 - val_loss: 0.9512 - val_accuracy: 0.7886\n",
            "Epoch 490/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1440 - accuracy: 0.9389 - val_loss: 0.9591 - val_accuracy: 0.7480\n",
            "Epoch 491/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0841 - accuracy: 0.9735 - val_loss: 1.0504 - val_accuracy: 0.7805\n",
            "Epoch 492/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1125 - accuracy: 0.9572 - val_loss: 1.0527 - val_accuracy: 0.7480\n",
            "Epoch 493/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9267 - val_loss: 1.0760 - val_accuracy: 0.7317\n",
            "Epoch 494/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1582 - accuracy: 0.9226 - val_loss: 1.0570 - val_accuracy: 0.7398\n",
            "Epoch 495/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0957 - accuracy: 0.9715 - val_loss: 0.9998 - val_accuracy: 0.7398\n",
            "Epoch 496/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0738 - accuracy: 0.9776 - val_loss: 1.0235 - val_accuracy: 0.7561\n",
            "Epoch 497/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1137 - accuracy: 0.9491 - val_loss: 1.1271 - val_accuracy: 0.7480\n",
            "Epoch 498/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0969 - accuracy: 0.9735 - val_loss: 1.0109 - val_accuracy: 0.7398\n",
            "Epoch 499/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2752 - accuracy: 0.9022 - val_loss: 1.0926 - val_accuracy: 0.6992\n",
            "Epoch 500/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2010 - accuracy: 0.9124 - val_loss: 0.9854 - val_accuracy: 0.7073\n",
            "Epoch 501/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1663 - accuracy: 0.9409 - val_loss: 1.1120 - val_accuracy: 0.7073\n",
            "Epoch 502/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1577 - accuracy: 0.9491 - val_loss: 1.0711 - val_accuracy: 0.7642\n",
            "Epoch 503/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1581 - accuracy: 0.9369 - val_loss: 0.9428 - val_accuracy: 0.7154\n",
            "Epoch 504/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0800 - accuracy: 0.9735 - val_loss: 0.9975 - val_accuracy: 0.7398\n",
            "Epoch 505/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0746 - accuracy: 0.9715 - val_loss: 1.0477 - val_accuracy: 0.6911\n",
            "Epoch 506/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0800 - accuracy: 0.9735 - val_loss: 1.1091 - val_accuracy: 0.7724\n",
            "Epoch 507/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1852 - accuracy: 0.9165 - val_loss: 1.1500 - val_accuracy: 0.7398\n",
            "Epoch 508/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2062 - accuracy: 0.9246 - val_loss: 1.5542 - val_accuracy: 0.7073\n",
            "Epoch 509/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2668 - accuracy: 0.9022 - val_loss: 0.8857 - val_accuracy: 0.7642\n",
            "Epoch 510/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1200 - accuracy: 0.9532 - val_loss: 0.9738 - val_accuracy: 0.7154\n",
            "Epoch 511/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0904 - accuracy: 0.9735 - val_loss: 1.0776 - val_accuracy: 0.7154\n",
            "Epoch 512/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1330 - accuracy: 0.9532 - val_loss: 0.9343 - val_accuracy: 0.7561\n",
            "Epoch 513/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1810 - accuracy: 0.9348 - val_loss: 0.8944 - val_accuracy: 0.7724\n",
            "Epoch 514/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 0.9837 - val_loss: 1.0093 - val_accuracy: 0.7398\n",
            "Epoch 515/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9735 - val_loss: 1.1041 - val_accuracy: 0.7317\n",
            "Epoch 516/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1231 - accuracy: 0.9633 - val_loss: 1.0990 - val_accuracy: 0.7073\n",
            "Epoch 517/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1144 - accuracy: 0.9552 - val_loss: 1.0614 - val_accuracy: 0.7317\n",
            "Epoch 518/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9593 - val_loss: 1.0159 - val_accuracy: 0.7642\n",
            "Epoch 519/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1047 - accuracy: 0.9654 - val_loss: 0.9961 - val_accuracy: 0.6911\n",
            "Epoch 520/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0748 - accuracy: 0.9715 - val_loss: 1.0721 - val_accuracy: 0.7561\n",
            "Epoch 521/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1431 - accuracy: 0.9491 - val_loss: 1.1525 - val_accuracy: 0.7317\n",
            "Epoch 522/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2532 - accuracy: 0.9063 - val_loss: 1.0481 - val_accuracy: 0.6992\n",
            "Epoch 523/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1952 - accuracy: 0.9287 - val_loss: 1.0328 - val_accuracy: 0.7154\n",
            "Epoch 524/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9695 - val_loss: 0.8947 - val_accuracy: 0.7480\n",
            "Epoch 525/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0734 - accuracy: 0.9735 - val_loss: 0.9404 - val_accuracy: 0.7724\n",
            "Epoch 526/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 0.9857 - val_loss: 1.1034 - val_accuracy: 0.7480\n",
            "Epoch 527/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 1.1088 - val_accuracy: 0.7317\n",
            "Epoch 528/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.9735 - val_loss: 1.1701 - val_accuracy: 0.7317\n",
            "Epoch 529/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1021 - accuracy: 0.9674 - val_loss: 1.1280 - val_accuracy: 0.6911\n",
            "Epoch 530/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.4553 - accuracy: 0.8534 - val_loss: 0.8974 - val_accuracy: 0.7317\n",
            "Epoch 531/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1725 - accuracy: 0.9287 - val_loss: 0.8904 - val_accuracy: 0.7317\n",
            "Epoch 532/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0826 - accuracy: 0.9695 - val_loss: 0.9454 - val_accuracy: 0.7236\n",
            "Epoch 533/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0759 - accuracy: 0.9756 - val_loss: 1.0171 - val_accuracy: 0.7480\n",
            "Epoch 534/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0682 - accuracy: 0.9796 - val_loss: 1.0078 - val_accuracy: 0.7561\n",
            "Epoch 535/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2278 - accuracy: 0.9165 - val_loss: 0.9102 - val_accuracy: 0.7724\n",
            "Epoch 536/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0958 - accuracy: 0.9674 - val_loss: 1.0305 - val_accuracy: 0.7154\n",
            "Epoch 537/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0749 - accuracy: 0.9735 - val_loss: 1.1049 - val_accuracy: 0.6992\n",
            "Epoch 538/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1004 - accuracy: 0.9593 - val_loss: 1.1580 - val_accuracy: 0.7480\n",
            "Epoch 539/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9796 - val_loss: 1.1905 - val_accuracy: 0.7398\n",
            "Epoch 540/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0406 - accuracy: 0.9898 - val_loss: 1.1660 - val_accuracy: 0.7642\n",
            "Epoch 541/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0379 - accuracy: 0.9898 - val_loss: 1.2120 - val_accuracy: 0.7398\n",
            "Epoch 542/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0372 - accuracy: 0.9898 - val_loss: 1.3195 - val_accuracy: 0.7398\n",
            "Epoch 543/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0503 - accuracy: 0.9857 - val_loss: 1.3209 - val_accuracy: 0.7154\n",
            "Epoch 544/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0387 - accuracy: 0.9898 - val_loss: 1.3381 - val_accuracy: 0.7073\n",
            "Epoch 545/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0350 - accuracy: 0.9898 - val_loss: 1.4021 - val_accuracy: 0.7398\n",
            "Epoch 546/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.4274 - accuracy: 0.8656 - val_loss: 0.9667 - val_accuracy: 0.7561\n",
            "Epoch 547/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2669 - accuracy: 0.8880 - val_loss: 0.9553 - val_accuracy: 0.7398\n",
            "Epoch 548/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1277 - accuracy: 0.9491 - val_loss: 0.9993 - val_accuracy: 0.6829\n",
            "Epoch 549/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0549 - accuracy: 0.9878 - val_loss: 1.0066 - val_accuracy: 0.7154\n",
            "Epoch 550/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0444 - accuracy: 0.9898 - val_loss: 1.0202 - val_accuracy: 0.7073\n",
            "Epoch 551/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1518 - accuracy: 0.9430 - val_loss: 1.0144 - val_accuracy: 0.7317\n",
            "Epoch 552/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1295 - accuracy: 0.9491 - val_loss: 1.1840 - val_accuracy: 0.7480\n",
            "Epoch 553/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1596 - accuracy: 0.9369 - val_loss: 1.0791 - val_accuracy: 0.7561\n",
            "Epoch 554/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0989 - accuracy: 0.9654 - val_loss: 1.0152 - val_accuracy: 0.7642\n",
            "Epoch 555/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0933 - accuracy: 0.9613 - val_loss: 1.0241 - val_accuracy: 0.7561\n",
            "Epoch 556/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0481 - accuracy: 0.9878 - val_loss: 1.1023 - val_accuracy: 0.7154\n",
            "Epoch 557/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0415 - accuracy: 0.9898 - val_loss: 1.1471 - val_accuracy: 0.7073\n",
            "Epoch 558/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0863 - accuracy: 0.9735 - val_loss: 1.1174 - val_accuracy: 0.7236\n",
            "Epoch 559/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1595 - accuracy: 0.9450 - val_loss: 1.2345 - val_accuracy: 0.7236\n",
            "Epoch 560/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1357 - accuracy: 0.9450 - val_loss: 1.1433 - val_accuracy: 0.6992\n",
            "Epoch 561/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0725 - accuracy: 0.9756 - val_loss: 1.1639 - val_accuracy: 0.7317\n",
            "Epoch 562/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9898 - val_loss: 1.2198 - val_accuracy: 0.7073\n",
            "Epoch 563/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0405 - accuracy: 0.9857 - val_loss: 1.1599 - val_accuracy: 0.6992\n",
            "Epoch 564/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0335 - accuracy: 0.9919 - val_loss: 1.2461 - val_accuracy: 0.7154\n",
            "Epoch 565/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9939 - val_loss: 1.3104 - val_accuracy: 0.7480\n",
            "Epoch 566/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0508 - accuracy: 0.9817 - val_loss: 1.5071 - val_accuracy: 0.7317\n",
            "Epoch 567/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3270 - accuracy: 0.8982 - val_loss: 1.0945 - val_accuracy: 0.7724\n",
            "Epoch 568/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0756 - accuracy: 0.9796 - val_loss: 1.0478 - val_accuracy: 0.7317\n",
            "Epoch 569/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0916 - accuracy: 0.9654 - val_loss: 1.1332 - val_accuracy: 0.7398\n",
            "Epoch 570/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1095 - accuracy: 0.9470 - val_loss: 1.1213 - val_accuracy: 0.7398\n",
            "Epoch 571/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0978 - accuracy: 0.9654 - val_loss: 1.1167 - val_accuracy: 0.7398\n",
            "Epoch 572/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9919 - val_loss: 1.2024 - val_accuracy: 0.7398\n",
            "Epoch 573/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 1.1157 - val_accuracy: 0.7561\n",
            "Epoch 574/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.9532 - val_loss: 1.1930 - val_accuracy: 0.6992\n",
            "Epoch 575/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1412 - accuracy: 0.9430 - val_loss: 1.1109 - val_accuracy: 0.6992\n",
            "Epoch 576/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0381 - accuracy: 0.9919 - val_loss: 1.1087 - val_accuracy: 0.7317\n",
            "Epoch 577/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1142 - accuracy: 0.9491 - val_loss: 1.1232 - val_accuracy: 0.7561\n",
            "Epoch 578/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0990 - accuracy: 0.9572 - val_loss: 1.1696 - val_accuracy: 0.7236\n",
            "Epoch 579/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 1.1911 - val_accuracy: 0.7561\n",
            "Epoch 580/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0440 - accuracy: 0.9817 - val_loss: 1.3005 - val_accuracy: 0.7236\n",
            "Epoch 581/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0444 - accuracy: 0.9857 - val_loss: 1.3032 - val_accuracy: 0.7236\n",
            "Epoch 582/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 1.3024 - val_accuracy: 0.7236\n",
            "Epoch 583/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.5107 - accuracy: 0.8432 - val_loss: 0.9796 - val_accuracy: 0.7398\n",
            "Epoch 584/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.9267 - val_loss: 0.8586 - val_accuracy: 0.7805\n",
            "Epoch 585/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9674 - val_loss: 0.9495 - val_accuracy: 0.7642\n",
            "Epoch 586/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 1.0640 - val_accuracy: 0.7317\n",
            "Epoch 587/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0322 - accuracy: 0.9939 - val_loss: 1.1433 - val_accuracy: 0.7561\n",
            "Epoch 588/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 1.2173 - val_accuracy: 0.7236\n",
            "Epoch 589/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9898 - val_loss: 1.2307 - val_accuracy: 0.7561\n",
            "Epoch 590/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0505 - accuracy: 0.9857 - val_loss: 1.1684 - val_accuracy: 0.7724\n",
            "Epoch 591/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0486 - accuracy: 0.9857 - val_loss: 1.2119 - val_accuracy: 0.7805\n",
            "Epoch 592/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 1.2973 - val_accuracy: 0.7480\n",
            "Epoch 593/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 1.3226 - val_accuracy: 0.7317\n",
            "Epoch 594/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 1.3813 - val_accuracy: 0.7480\n",
            "Epoch 595/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 1.4176 - val_accuracy: 0.7561\n",
            "Epoch 596/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0148 - accuracy: 0.9939 - val_loss: 1.3980 - val_accuracy: 0.7480\n",
            "Epoch 597/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9939 - val_loss: 1.4829 - val_accuracy: 0.7398\n",
            "Epoch 598/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 1.4459 - val_accuracy: 0.7317\n",
            "Epoch 599/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 1.5058 - val_accuracy: 0.7398\n",
            "Epoch 600/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.9939 - val_loss: 1.5494 - val_accuracy: 0.7154\n",
            "Epoch 601/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0129 - accuracy: 0.9939 - val_loss: 1.5839 - val_accuracy: 0.7398\n",
            "Epoch 602/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 1.5876 - val_accuracy: 0.7398\n",
            "Epoch 603/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0131 - accuracy: 0.9939 - val_loss: 1.6226 - val_accuracy: 0.7398\n",
            "Epoch 604/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9939 - val_loss: 1.6440 - val_accuracy: 0.7398\n",
            "Epoch 605/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0559 - accuracy: 0.9878 - val_loss: 1.7116 - val_accuracy: 0.7073\n",
            "Epoch 606/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.3566 - accuracy: 0.8859 - val_loss: 1.2801 - val_accuracy: 0.7317\n",
            "Epoch 607/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.3331 - accuracy: 0.8758 - val_loss: 1.1381 - val_accuracy: 0.7724\n",
            "Epoch 608/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1826 - accuracy: 0.9206 - val_loss: 1.0149 - val_accuracy: 0.7073\n",
            "Epoch 609/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0713 - accuracy: 0.9695 - val_loss: 0.9990 - val_accuracy: 0.7561\n",
            "Epoch 610/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0589 - accuracy: 0.9776 - val_loss: 1.1463 - val_accuracy: 0.7073\n",
            "Epoch 611/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0382 - accuracy: 0.9898 - val_loss: 1.2290 - val_accuracy: 0.7154\n",
            "Epoch 612/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0671 - accuracy: 0.9776 - val_loss: 1.2760 - val_accuracy: 0.7154\n",
            "Epoch 613/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1226 - accuracy: 0.9532 - val_loss: 1.3250 - val_accuracy: 0.7561\n",
            "Epoch 614/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1370 - accuracy: 0.9511 - val_loss: 1.2630 - val_accuracy: 0.7317\n",
            "Epoch 615/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0403 - accuracy: 0.9837 - val_loss: 1.3414 - val_accuracy: 0.7073\n",
            "Epoch 616/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 1.2993 - val_accuracy: 0.7317\n",
            "Epoch 617/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1751 - accuracy: 0.9430 - val_loss: 1.1793 - val_accuracy: 0.7561\n",
            "Epoch 618/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1758 - accuracy: 0.9430 - val_loss: 1.3354 - val_accuracy: 0.6911\n",
            "Epoch 619/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1449 - accuracy: 0.9409 - val_loss: 1.1432 - val_accuracy: 0.7073\n",
            "Epoch 620/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9857 - val_loss: 1.2037 - val_accuracy: 0.7398\n",
            "Epoch 621/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0369 - accuracy: 0.9857 - val_loss: 1.2331 - val_accuracy: 0.7480\n",
            "Epoch 622/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0248 - accuracy: 0.9919 - val_loss: 1.2843 - val_accuracy: 0.7154\n",
            "Epoch 623/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 1.3738 - val_accuracy: 0.7317\n",
            "Epoch 624/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 1.4180 - val_accuracy: 0.7236\n",
            "Epoch 625/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 1.4064 - val_accuracy: 0.7317\n",
            "Epoch 626/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1861 - accuracy: 0.9369 - val_loss: 1.3054 - val_accuracy: 0.7805\n",
            "Epoch 627/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.4966 - accuracy: 0.8248 - val_loss: 0.9154 - val_accuracy: 0.7642\n",
            "Epoch 628/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2728 - accuracy: 0.8961 - val_loss: 0.8846 - val_accuracy: 0.7154\n",
            "Epoch 629/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0849 - accuracy: 0.9776 - val_loss: 1.0021 - val_accuracy: 0.7480\n",
            "Epoch 630/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0516 - accuracy: 0.9837 - val_loss: 1.0526 - val_accuracy: 0.7236\n",
            "Epoch 631/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0501 - accuracy: 0.9857 - val_loss: 1.1539 - val_accuracy: 0.7236\n",
            "Epoch 632/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0403 - accuracy: 0.9878 - val_loss: 1.1976 - val_accuracy: 0.7317\n",
            "Epoch 633/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 1.2411 - val_accuracy: 0.7154\n",
            "Epoch 634/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 1.2715 - val_accuracy: 0.7317\n",
            "Epoch 635/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 1.3073 - val_accuracy: 0.7480\n",
            "Epoch 636/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 1.3698 - val_accuracy: 0.7317\n",
            "Epoch 637/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0136 - accuracy: 0.9939 - val_loss: 1.4266 - val_accuracy: 0.7236\n",
            "Epoch 638/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0326 - accuracy: 0.9898 - val_loss: 1.4485 - val_accuracy: 0.7073\n",
            "Epoch 639/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2639 - accuracy: 0.9104 - val_loss: 1.1420 - val_accuracy: 0.7154\n",
            "Epoch 640/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2425 - accuracy: 0.9084 - val_loss: 1.0317 - val_accuracy: 0.7886\n",
            "Epoch 641/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1027 - accuracy: 0.9593 - val_loss: 1.0216 - val_accuracy: 0.7480\n",
            "Epoch 642/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0372 - accuracy: 0.9939 - val_loss: 1.0622 - val_accuracy: 0.7561\n",
            "Epoch 643/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 1.1312 - val_accuracy: 0.7480\n",
            "Epoch 644/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 1.2133 - val_accuracy: 0.7317\n",
            "Epoch 645/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 1.2243 - val_accuracy: 0.7561\n",
            "Epoch 646/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 1.3110 - val_accuracy: 0.7642\n",
            "Epoch 647/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 1.3131 - val_accuracy: 0.7154\n",
            "Epoch 648/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0180 - accuracy: 0.9980 - val_loss: 1.3656 - val_accuracy: 0.7398\n",
            "Epoch 649/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0444 - accuracy: 0.9878 - val_loss: 1.4101 - val_accuracy: 0.7317\n",
            "Epoch 650/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9959 - val_loss: 1.3861 - val_accuracy: 0.7480\n",
            "Epoch 651/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 1.4966 - val_accuracy: 0.7236\n",
            "Epoch 652/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1649 - accuracy: 0.9633 - val_loss: 1.4080 - val_accuracy: 0.6504\n",
            "Epoch 653/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2622 - accuracy: 0.8921 - val_loss: 1.3339 - val_accuracy: 0.7073\n",
            "Epoch 654/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1364 - accuracy: 0.9430 - val_loss: 1.1666 - val_accuracy: 0.7317\n",
            "Epoch 655/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0678 - accuracy: 0.9796 - val_loss: 1.2262 - val_accuracy: 0.7073\n",
            "Epoch 656/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0694 - accuracy: 0.9796 - val_loss: 1.2737 - val_accuracy: 0.7236\n",
            "Epoch 657/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0915 - accuracy: 0.9674 - val_loss: 1.1501 - val_accuracy: 0.7724\n",
            "Epoch 658/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0431 - accuracy: 0.9837 - val_loss: 1.2544 - val_accuracy: 0.7480\n",
            "Epoch 659/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 1.3182 - val_accuracy: 0.7398\n",
            "Epoch 660/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 1.4099 - val_accuracy: 0.6992\n",
            "Epoch 661/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.9980 - val_loss: 1.3835 - val_accuracy: 0.7398\n",
            "Epoch 662/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.9919 - val_loss: 1.4354 - val_accuracy: 0.7154\n",
            "Epoch 663/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 1.4706 - val_accuracy: 0.7480\n",
            "Epoch 664/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 1.4268 - val_accuracy: 0.7398\n",
            "Epoch 665/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 1.5040 - val_accuracy: 0.7317\n",
            "Epoch 666/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0167 - accuracy: 0.9898 - val_loss: 1.4858 - val_accuracy: 0.7236\n",
            "Epoch 667/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1442 - accuracy: 0.9593 - val_loss: 1.3975 - val_accuracy: 0.7236\n",
            "Epoch 668/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0796 - accuracy: 0.9715 - val_loss: 1.3691 - val_accuracy: 0.7073\n",
            "Epoch 669/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0239 - accuracy: 0.9959 - val_loss: 1.3317 - val_accuracy: 0.7398\n",
            "Epoch 670/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3218 - accuracy: 0.8880 - val_loss: 1.4514 - val_accuracy: 0.6911\n",
            "Epoch 671/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2323 - accuracy: 0.9063 - val_loss: 1.0445 - val_accuracy: 0.7236\n",
            "Epoch 672/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0544 - accuracy: 0.9796 - val_loss: 1.1708 - val_accuracy: 0.7154\n",
            "Epoch 673/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0613 - accuracy: 0.9796 - val_loss: 1.3126 - val_accuracy: 0.7398\n",
            "Epoch 674/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 0.9776 - val_loss: 1.1687 - val_accuracy: 0.7317\n",
            "Epoch 675/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0753 - accuracy: 0.9735 - val_loss: 1.2155 - val_accuracy: 0.7236\n",
            "Epoch 676/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 1.2932 - val_accuracy: 0.7480\n",
            "Epoch 677/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9919 - val_loss: 1.2450 - val_accuracy: 0.7480\n",
            "Epoch 678/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.2982 - val_accuracy: 0.7317\n",
            "Epoch 679/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 1.4005 - val_accuracy: 0.7398\n",
            "Epoch 680/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 1.4325 - val_accuracy: 0.7236\n",
            "Epoch 681/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.9980 - val_loss: 1.4340 - val_accuracy: 0.7236\n",
            "Epoch 682/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.4939 - val_accuracy: 0.7317\n",
            "Epoch 683/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 1.5105 - val_accuracy: 0.7317\n",
            "Epoch 684/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 1.5455 - val_accuracy: 0.7317\n",
            "Epoch 685/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 1.5507 - val_accuracy: 0.7398\n",
            "Epoch 686/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5836 - val_accuracy: 0.7317\n",
            "Epoch 687/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.5762 - val_accuracy: 0.7398\n",
            "Epoch 688/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 1.6321 - val_accuracy: 0.7398\n",
            "Epoch 689/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.2359 - accuracy: 0.9389 - val_loss: 1.4577 - val_accuracy: 0.6911\n",
            "Epoch 690/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.3670 - accuracy: 0.8758 - val_loss: 0.9879 - val_accuracy: 0.7480\n",
            "Epoch 691/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1699 - accuracy: 0.9267 - val_loss: 1.0271 - val_accuracy: 0.7317\n",
            "Epoch 692/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0580 - accuracy: 0.9857 - val_loss: 1.0992 - val_accuracy: 0.7398\n",
            "Epoch 693/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0329 - accuracy: 0.9939 - val_loss: 1.1866 - val_accuracy: 0.7642\n",
            "Epoch 694/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0212 - accuracy: 0.9959 - val_loss: 1.2566 - val_accuracy: 0.7398\n",
            "Epoch 695/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.3182 - val_accuracy: 0.7398\n",
            "Epoch 696/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1676 - accuracy: 0.9389 - val_loss: 1.2487 - val_accuracy: 0.7724\n",
            "Epoch 697/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2200 - accuracy: 0.9145 - val_loss: 1.0756 - val_accuracy: 0.7480\n",
            "Epoch 698/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1231 - accuracy: 0.9511 - val_loss: 1.1192 - val_accuracy: 0.7317\n",
            "Epoch 699/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0916 - accuracy: 0.9776 - val_loss: 1.1363 - val_accuracy: 0.7073\n",
            "Epoch 700/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0324 - accuracy: 0.9939 - val_loss: 1.2153 - val_accuracy: 0.7154\n",
            "Epoch 701/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0275 - accuracy: 0.9939 - val_loss: 1.1722 - val_accuracy: 0.7480\n",
            "Epoch 702/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0558 - accuracy: 0.9776 - val_loss: 1.2365 - val_accuracy: 0.7480\n",
            "Epoch 703/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0558 - accuracy: 0.9776 - val_loss: 1.2284 - val_accuracy: 0.7398\n",
            "Epoch 704/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0346 - accuracy: 0.9898 - val_loss: 1.3908 - val_accuracy: 0.6992\n",
            "Epoch 705/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 1.3126 - val_accuracy: 0.7398\n",
            "Epoch 706/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 1.3869 - val_accuracy: 0.7480\n",
            "Epoch 707/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 1.3874 - val_accuracy: 0.7236\n",
            "Epoch 708/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4057 - val_accuracy: 0.7236\n",
            "Epoch 709/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 1.4227 - val_accuracy: 0.7317\n",
            "Epoch 710/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 1.5032 - val_accuracy: 0.6992\n",
            "Epoch 711/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.4876 - val_accuracy: 0.7317\n",
            "Epoch 712/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9959 - val_loss: 1.5259 - val_accuracy: 0.7317\n",
            "Epoch 713/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 1.5778 - val_accuracy: 0.6992\n",
            "Epoch 714/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9980 - val_loss: 1.4859 - val_accuracy: 0.7236\n",
            "Epoch 715/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0210 - accuracy: 0.9919 - val_loss: 1.5725 - val_accuracy: 0.6911\n",
            "Epoch 716/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.7127 - val_accuracy: 0.7154\n",
            "Epoch 717/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.4008 - accuracy: 0.8961 - val_loss: 1.2408 - val_accuracy: 0.7317\n",
            "Epoch 718/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1678 - accuracy: 0.9470 - val_loss: 1.2961 - val_accuracy: 0.7073\n",
            "Epoch 719/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0867 - accuracy: 0.9674 - val_loss: 1.1732 - val_accuracy: 0.7480\n",
            "Epoch 720/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1100 - accuracy: 0.9491 - val_loss: 1.1560 - val_accuracy: 0.7154\n",
            "Epoch 721/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1468 - accuracy: 0.9532 - val_loss: 1.0707 - val_accuracy: 0.7317\n",
            "Epoch 722/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0359 - accuracy: 0.9939 - val_loss: 1.1393 - val_accuracy: 0.7480\n",
            "Epoch 723/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0208 - accuracy: 0.9959 - val_loss: 1.1937 - val_accuracy: 0.7480\n",
            "Epoch 724/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 1.2421 - val_accuracy: 0.7317\n",
            "Epoch 725/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 1.2775 - val_accuracy: 0.7480\n",
            "Epoch 726/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 1.2915 - val_accuracy: 0.7398\n",
            "Epoch 727/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 1.3857 - val_accuracy: 0.7236\n",
            "Epoch 728/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9430 - val_loss: 1.2504 - val_accuracy: 0.6504\n",
            "Epoch 729/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1227 - accuracy: 0.9572 - val_loss: 1.1584 - val_accuracy: 0.7236\n",
            "Epoch 730/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0548 - accuracy: 0.9817 - val_loss: 1.2037 - val_accuracy: 0.7073\n",
            "Epoch 731/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0248 - accuracy: 0.9959 - val_loss: 1.2857 - val_accuracy: 0.7073\n",
            "Epoch 732/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0283 - accuracy: 0.9959 - val_loss: 1.2900 - val_accuracy: 0.7236\n",
            "Epoch 733/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3291 - val_accuracy: 0.7236\n",
            "Epoch 734/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 1.3300 - val_accuracy: 0.7480\n",
            "Epoch 735/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1062 - accuracy: 0.9674 - val_loss: 1.2757 - val_accuracy: 0.7154\n",
            "Epoch 736/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.3022 - accuracy: 0.8941 - val_loss: 1.0653 - val_accuracy: 0.7317\n",
            "Epoch 737/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0958 - accuracy: 0.9674 - val_loss: 1.0330 - val_accuracy: 0.7317\n",
            "Epoch 738/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0414 - accuracy: 0.9878 - val_loss: 1.1040 - val_accuracy: 0.7154\n",
            "Epoch 739/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.1928 - val_accuracy: 0.7236\n",
            "Epoch 740/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0180 - accuracy: 0.9980 - val_loss: 1.2336 - val_accuracy: 0.7317\n",
            "Epoch 741/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3012 - val_accuracy: 0.7154\n",
            "Epoch 742/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 1.3016 - val_accuracy: 0.7317\n",
            "Epoch 743/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 1.3202 - val_accuracy: 0.7236\n",
            "Epoch 744/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 1.3327 - val_accuracy: 0.7398\n",
            "Epoch 745/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3624 - val_accuracy: 0.7317\n",
            "Epoch 746/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.3869 - val_accuracy: 0.7236\n",
            "Epoch 747/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.4100 - val_accuracy: 0.7317\n",
            "Epoch 748/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0850 - accuracy: 0.9756 - val_loss: 1.2779 - val_accuracy: 0.7398\n",
            "Epoch 749/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.2019 - accuracy: 0.9369 - val_loss: 1.1998 - val_accuracy: 0.7317\n",
            "Epoch 750/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9613 - val_loss: 1.1124 - val_accuracy: 0.7480\n",
            "Epoch 751/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0217 - accuracy: 0.9980 - val_loss: 1.2270 - val_accuracy: 0.7236\n",
            "Epoch 752/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 1.2902 - val_accuracy: 0.7073\n",
            "Epoch 753/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.3531 - val_accuracy: 0.7154\n",
            "Epoch 754/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.3704 - val_accuracy: 0.7154\n",
            "Epoch 755/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.4132 - val_accuracy: 0.7236\n",
            "Epoch 756/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.4506 - val_accuracy: 0.7073\n",
            "Epoch 757/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.4703 - val_accuracy: 0.7154\n",
            "Epoch 758/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4907 - val_accuracy: 0.7154\n",
            "Epoch 759/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.5152 - val_accuracy: 0.7154\n",
            "Epoch 760/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5277 - val_accuracy: 0.7154\n",
            "Epoch 761/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5496 - val_accuracy: 0.7154\n",
            "Epoch 762/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.7154\n",
            "Epoch 763/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.5678 - val_accuracy: 0.7154\n",
            "Epoch 764/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0149 - accuracy: 0.9980 - val_loss: 1.6471 - val_accuracy: 0.7073\n",
            "Epoch 765/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6312 - val_accuracy: 0.7073\n",
            "Epoch 766/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.6418 - val_accuracy: 0.6992\n",
            "Epoch 767/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.6579 - val_accuracy: 0.7073\n",
            "Epoch 768/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.6514 - val_accuracy: 0.7154\n",
            "Epoch 769/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.6943 - val_accuracy: 0.7073\n",
            "Epoch 770/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.7002 - val_accuracy: 0.6992\n",
            "Epoch 771/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7131 - val_accuracy: 0.7073\n",
            "Epoch 772/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.7275 - val_accuracy: 0.7073\n",
            "Epoch 773/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7246 - val_accuracy: 0.7073\n",
            "Epoch 774/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.7388 - val_accuracy: 0.7073\n",
            "Epoch 775/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7518 - val_accuracy: 0.7073\n",
            "Epoch 776/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.7073\n",
            "Epoch 777/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7760 - val_accuracy: 0.7073\n",
            "Epoch 778/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7859 - val_accuracy: 0.7073\n",
            "Epoch 779/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7919 - val_accuracy: 0.7073\n",
            "Epoch 780/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8059 - val_accuracy: 0.7073\n",
            "Epoch 781/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8167 - val_accuracy: 0.7073\n",
            "Epoch 782/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8261 - val_accuracy: 0.7073\n",
            "Epoch 783/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8346 - val_accuracy: 0.7073\n",
            "Epoch 784/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.8433 - val_accuracy: 0.7073\n",
            "Epoch 785/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8529 - val_accuracy: 0.7073\n",
            "Epoch 786/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.8623 - val_accuracy: 0.7154\n",
            "Epoch 787/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.8532 - val_accuracy: 0.7073\n",
            "Epoch 788/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8693 - val_accuracy: 0.7154\n",
            "Epoch 789/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8664 - val_accuracy: 0.7073\n",
            "Epoch 790/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8586 - val_accuracy: 0.7236\n",
            "Epoch 791/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8428 - val_accuracy: 0.7154\n",
            "Epoch 792/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.3396 - accuracy: 0.9206 - val_loss: 1.6393 - val_accuracy: 0.6911\n",
            "Epoch 793/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.3042 - accuracy: 0.8982 - val_loss: 1.0460 - val_accuracy: 0.7154\n",
            "Epoch 794/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1147 - accuracy: 0.9552 - val_loss: 1.2556 - val_accuracy: 0.7073\n",
            "Epoch 795/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0968 - accuracy: 0.9735 - val_loss: 1.2516 - val_accuracy: 0.7154\n",
            "Epoch 796/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0341 - accuracy: 0.9939 - val_loss: 1.4965 - val_accuracy: 0.6992\n",
            "Epoch 797/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.1588 - accuracy: 0.9409 - val_loss: 1.2396 - val_accuracy: 0.6992\n",
            "Epoch 798/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0318 - accuracy: 0.9939 - val_loss: 1.1873 - val_accuracy: 0.7236\n",
            "Epoch 799/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.2847 - val_accuracy: 0.7236\n",
            "Epoch 800/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3316 - val_accuracy: 0.7154\n",
            "Epoch 801/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.3660 - val_accuracy: 0.7236\n",
            "Epoch 802/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.3812 - val_accuracy: 0.7073\n",
            "Epoch 803/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.4087 - val_accuracy: 0.7073\n",
            "Epoch 804/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.4321 - val_accuracy: 0.7154\n",
            "Epoch 805/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.4715 - val_accuracy: 0.7154\n",
            "Epoch 806/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.4710 - val_accuracy: 0.7154\n",
            "Epoch 807/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5078 - val_accuracy: 0.6911\n",
            "Epoch 808/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.5309 - val_accuracy: 0.7073\n",
            "Epoch 809/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5386 - val_accuracy: 0.7073\n",
            "Epoch 810/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5656 - val_accuracy: 0.7073\n",
            "Epoch 811/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.5804 - val_accuracy: 0.7073\n",
            "Epoch 812/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5795 - val_accuracy: 0.7154\n",
            "Epoch 813/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6023 - val_accuracy: 0.7154\n",
            "Epoch 814/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6147 - val_accuracy: 0.7154\n",
            "Epoch 815/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6378 - val_accuracy: 0.7073\n",
            "Epoch 816/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6473 - val_accuracy: 0.7073\n",
            "Epoch 817/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6620 - val_accuracy: 0.7073\n",
            "Epoch 818/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6767 - val_accuracy: 0.7073\n",
            "Epoch 819/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6834 - val_accuracy: 0.7073\n",
            "Epoch 820/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6964 - val_accuracy: 0.7073\n",
            "Epoch 821/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7057 - val_accuracy: 0.7073\n",
            "Epoch 822/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7169 - val_accuracy: 0.7073\n",
            "Epoch 823/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7277 - val_accuracy: 0.7073\n",
            "Epoch 824/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7412 - val_accuracy: 0.6992\n",
            "Epoch 825/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7534 - val_accuracy: 0.7073\n",
            "Epoch 826/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7615 - val_accuracy: 0.7073\n",
            "Epoch 827/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7669 - val_accuracy: 0.7073\n",
            "Epoch 828/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.7073\n",
            "Epoch 829/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7864 - val_accuracy: 0.7073\n",
            "Epoch 830/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7983 - val_accuracy: 0.7073\n",
            "Epoch 831/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7976 - val_accuracy: 0.7073\n",
            "Epoch 832/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8109 - val_accuracy: 0.7073\n",
            "Epoch 833/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8170 - val_accuracy: 0.7073\n",
            "Epoch 834/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.8250 - val_accuracy: 0.7073\n",
            "Epoch 835/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8338 - val_accuracy: 0.7073\n",
            "Epoch 836/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.8385 - val_accuracy: 0.7073\n",
            "Epoch 837/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8434 - val_accuracy: 0.7073\n",
            "Epoch 838/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8557 - val_accuracy: 0.7073\n",
            "Epoch 839/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8629 - val_accuracy: 0.7073\n",
            "Epoch 840/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8697 - val_accuracy: 0.7073\n",
            "Epoch 841/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8771 - val_accuracy: 0.7073\n",
            "Epoch 842/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8809 - val_accuracy: 0.7073\n",
            "Epoch 843/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8850 - val_accuracy: 0.7073\n",
            "Epoch 844/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8878 - val_accuracy: 0.7073\n",
            "Epoch 845/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8950 - val_accuracy: 0.7073\n",
            "Epoch 846/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9038 - val_accuracy: 0.7073\n",
            "Epoch 847/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9084 - val_accuracy: 0.7073\n",
            "Epoch 848/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9151 - val_accuracy: 0.7073\n",
            "Epoch 849/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 9.7130e-04 - accuracy: 1.0000 - val_loss: 1.9193 - val_accuracy: 0.7073\n",
            "Epoch 850/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 9.4249e-04 - accuracy: 1.0000 - val_loss: 1.9246 - val_accuracy: 0.7073\n",
            "Epoch 851/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 9.5539e-04 - accuracy: 1.0000 - val_loss: 1.9299 - val_accuracy: 0.7073\n",
            "Epoch 852/1000\n",
            "246/246 [==============================] - 2s 7ms/step - loss: 9.8578e-04 - accuracy: 1.0000 - val_loss: 1.9380 - val_accuracy: 0.7073\n",
            "Epoch 853/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 9.1135e-04 - accuracy: 1.0000 - val_loss: 1.9421 - val_accuracy: 0.7073\n",
            "Epoch 854/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 8.8289e-04 - accuracy: 1.0000 - val_loss: 1.9479 - val_accuracy: 0.7073\n",
            "Epoch 855/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 8.6523e-04 - accuracy: 1.0000 - val_loss: 1.9572 - val_accuracy: 0.7073\n",
            "Epoch 856/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 8.5415e-04 - accuracy: 1.0000 - val_loss: 1.9625 - val_accuracy: 0.7073\n",
            "Epoch 857/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 8.3213e-04 - accuracy: 1.0000 - val_loss: 1.9683 - val_accuracy: 0.7073\n",
            "Epoch 858/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 8.1526e-04 - accuracy: 1.0000 - val_loss: 1.9743 - val_accuracy: 0.7073\n",
            "Epoch 859/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 7.9988e-04 - accuracy: 1.0000 - val_loss: 1.9795 - val_accuracy: 0.7073\n",
            "Epoch 860/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 8.0435e-04 - accuracy: 1.0000 - val_loss: 1.9835 - val_accuracy: 0.7073\n",
            "Epoch 861/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 9.7204e-04 - accuracy: 1.0000 - val_loss: 1.9829 - val_accuracy: 0.7073\n",
            "Epoch 862/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 8.0198e-04 - accuracy: 1.0000 - val_loss: 1.9872 - val_accuracy: 0.7073\n",
            "Epoch 863/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 7.7192e-04 - accuracy: 1.0000 - val_loss: 1.9924 - val_accuracy: 0.7073\n",
            "Epoch 864/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 7.5306e-04 - accuracy: 1.0000 - val_loss: 1.9972 - val_accuracy: 0.7073\n",
            "Epoch 865/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 7.3811e-04 - accuracy: 1.0000 - val_loss: 2.0044 - val_accuracy: 0.7073\n",
            "Epoch 866/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 7.2426e-04 - accuracy: 1.0000 - val_loss: 2.0092 - val_accuracy: 0.7073\n",
            "Epoch 867/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 7.1123e-04 - accuracy: 1.0000 - val_loss: 2.0139 - val_accuracy: 0.7073\n",
            "Epoch 868/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 6.9909e-04 - accuracy: 1.0000 - val_loss: 2.0211 - val_accuracy: 0.7073\n",
            "Epoch 869/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 6.8808e-04 - accuracy: 1.0000 - val_loss: 2.0272 - val_accuracy: 0.7073\n",
            "Epoch 870/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 6.7715e-04 - accuracy: 1.0000 - val_loss: 2.0316 - val_accuracy: 0.7073\n",
            "Epoch 871/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 6.7710e-04 - accuracy: 1.0000 - val_loss: 2.0300 - val_accuracy: 0.7073\n",
            "Epoch 872/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 6.7606e-04 - accuracy: 1.0000 - val_loss: 2.0381 - val_accuracy: 0.7073\n",
            "Epoch 873/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 7.2385e-04 - accuracy: 1.0000 - val_loss: 2.0416 - val_accuracy: 0.7073\n",
            "Epoch 874/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 6.7091e-04 - accuracy: 1.0000 - val_loss: 2.0447 - val_accuracy: 0.7073\n",
            "Epoch 875/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 6.5207e-04 - accuracy: 1.0000 - val_loss: 2.0486 - val_accuracy: 0.7073\n",
            "Epoch 876/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 6.3881e-04 - accuracy: 1.0000 - val_loss: 2.0526 - val_accuracy: 0.7073\n",
            "Epoch 877/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 6.2733e-04 - accuracy: 1.0000 - val_loss: 2.0566 - val_accuracy: 0.7073\n",
            "Epoch 878/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 6.1670e-04 - accuracy: 1.0000 - val_loss: 2.0624 - val_accuracy: 0.7073\n",
            "Epoch 879/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 6.0715e-04 - accuracy: 1.0000 - val_loss: 2.0633 - val_accuracy: 0.7073\n",
            "Epoch 880/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 7.0723e-04 - accuracy: 1.0000 - val_loss: 2.0661 - val_accuracy: 0.7073\n",
            "Epoch 881/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 6.0066e-04 - accuracy: 1.0000 - val_loss: 2.0692 - val_accuracy: 0.7073\n",
            "Epoch 882/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 5.8999e-04 - accuracy: 1.0000 - val_loss: 2.0739 - val_accuracy: 0.7073\n",
            "Epoch 883/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 5.8005e-04 - accuracy: 1.0000 - val_loss: 2.0791 - val_accuracy: 0.7073\n",
            "Epoch 884/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 5.7341e-04 - accuracy: 1.0000 - val_loss: 2.0842 - val_accuracy: 0.7073\n",
            "Epoch 885/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 5.7448e-04 - accuracy: 1.0000 - val_loss: 2.0867 - val_accuracy: 0.7073\n",
            "Epoch 886/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 5.6498e-04 - accuracy: 1.0000 - val_loss: 2.0897 - val_accuracy: 0.7073\n",
            "Epoch 887/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 5.5455e-04 - accuracy: 1.0000 - val_loss: 2.0978 - val_accuracy: 0.7073\n",
            "Epoch 888/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 7.0490e-04 - accuracy: 1.0000 - val_loss: 2.1097 - val_accuracy: 0.7073\n",
            "Epoch 889/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 5.5843e-04 - accuracy: 1.0000 - val_loss: 2.1117 - val_accuracy: 0.7073\n",
            "Epoch 890/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 5.4583e-04 - accuracy: 1.0000 - val_loss: 2.1137 - val_accuracy: 0.7073\n",
            "Epoch 891/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 5.3554e-04 - accuracy: 1.0000 - val_loss: 2.1167 - val_accuracy: 0.7073\n",
            "Epoch 892/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 5.3069e-04 - accuracy: 1.0000 - val_loss: 2.1173 - val_accuracy: 0.7073\n",
            "Epoch 893/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 5.8575e-04 - accuracy: 1.0000 - val_loss: 2.1202 - val_accuracy: 0.7073\n",
            "Epoch 894/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 5.2288e-04 - accuracy: 1.0000 - val_loss: 2.1229 - val_accuracy: 0.7073\n",
            "Epoch 895/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 5.1310e-04 - accuracy: 1.0000 - val_loss: 2.1249 - val_accuracy: 0.7073\n",
            "Epoch 896/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 5.0508e-04 - accuracy: 1.0000 - val_loss: 2.1288 - val_accuracy: 0.7073\n",
            "Epoch 897/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 4.9841e-04 - accuracy: 1.0000 - val_loss: 2.1274 - val_accuracy: 0.7073\n",
            "Epoch 898/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 5.0146e-04 - accuracy: 1.0000 - val_loss: 2.1306 - val_accuracy: 0.7073\n",
            "Epoch 899/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 4.9138e-04 - accuracy: 1.0000 - val_loss: 2.1357 - val_accuracy: 0.7073\n",
            "Epoch 900/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 4.8381e-04 - accuracy: 1.0000 - val_loss: 2.1395 - val_accuracy: 0.7073\n",
            "Epoch 901/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 4.7849e-04 - accuracy: 1.0000 - val_loss: 2.1470 - val_accuracy: 0.7073\n",
            "Epoch 902/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 5.1649e-04 - accuracy: 1.0000 - val_loss: 2.1451 - val_accuracy: 0.7073\n",
            "Epoch 903/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 4.9525e-04 - accuracy: 1.0000 - val_loss: 2.1512 - val_accuracy: 0.7073\n",
            "Epoch 904/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 4.7071e-04 - accuracy: 1.0000 - val_loss: 2.1550 - val_accuracy: 0.7073\n",
            "Epoch 905/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 4.6293e-04 - accuracy: 1.0000 - val_loss: 2.1593 - val_accuracy: 0.7073\n",
            "Epoch 906/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 4.5534e-04 - accuracy: 1.0000 - val_loss: 2.1629 - val_accuracy: 0.7073\n",
            "Epoch 907/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 4.5122e-04 - accuracy: 1.0000 - val_loss: 2.1642 - val_accuracy: 0.7073\n",
            "Epoch 908/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 4.4946e-04 - accuracy: 1.0000 - val_loss: 2.1661 - val_accuracy: 0.7073\n",
            "Epoch 909/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 4.4637e-04 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 0.7073\n",
            "Epoch 910/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 4.3804e-04 - accuracy: 1.0000 - val_loss: 2.1737 - val_accuracy: 0.7073\n",
            "Epoch 911/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 4.3300e-04 - accuracy: 1.0000 - val_loss: 2.1767 - val_accuracy: 0.7073\n",
            "Epoch 912/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 4.2775e-04 - accuracy: 1.0000 - val_loss: 2.1796 - val_accuracy: 0.7073\n",
            "Epoch 913/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 4.3188e-04 - accuracy: 1.0000 - val_loss: 2.1861 - val_accuracy: 0.7073\n",
            "Epoch 914/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 4.2767e-04 - accuracy: 1.0000 - val_loss: 2.1884 - val_accuracy: 0.7073\n",
            "Epoch 915/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 4.4141e-04 - accuracy: 1.0000 - val_loss: 2.1941 - val_accuracy: 0.7073\n",
            "Epoch 916/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 4.1699e-04 - accuracy: 1.0000 - val_loss: 2.1957 - val_accuracy: 0.7073\n",
            "Epoch 917/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 4.1108e-04 - accuracy: 1.0000 - val_loss: 2.1988 - val_accuracy: 0.7073\n",
            "Epoch 918/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 4.0951e-04 - accuracy: 1.0000 - val_loss: 2.1972 - val_accuracy: 0.7073\n",
            "Epoch 919/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 4.0655e-04 - accuracy: 1.0000 - val_loss: 2.1992 - val_accuracy: 0.7073\n",
            "Epoch 920/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 4.0469e-04 - accuracy: 1.0000 - val_loss: 2.2042 - val_accuracy: 0.7073\n",
            "Epoch 921/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.9798e-04 - accuracy: 1.0000 - val_loss: 2.2071 - val_accuracy: 0.7073\n",
            "Epoch 922/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.9494e-04 - accuracy: 1.0000 - val_loss: 2.2143 - val_accuracy: 0.7073\n",
            "Epoch 923/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 4.2109e-04 - accuracy: 1.0000 - val_loss: 2.2118 - val_accuracy: 0.7073\n",
            "Epoch 924/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 4.2126e-04 - accuracy: 1.0000 - val_loss: 2.2155 - val_accuracy: 0.7073\n",
            "Epoch 925/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.8681e-04 - accuracy: 1.0000 - val_loss: 2.2175 - val_accuracy: 0.7073\n",
            "Epoch 926/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.8157e-04 - accuracy: 1.0000 - val_loss: 2.2200 - val_accuracy: 0.7073\n",
            "Epoch 927/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.7741e-04 - accuracy: 1.0000 - val_loss: 2.2232 - val_accuracy: 0.7073\n",
            "Epoch 928/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.7544e-04 - accuracy: 1.0000 - val_loss: 2.2279 - val_accuracy: 0.7073\n",
            "Epoch 929/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.8433e-04 - accuracy: 1.0000 - val_loss: 2.2251 - val_accuracy: 0.7073\n",
            "Epoch 930/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.7170e-04 - accuracy: 1.0000 - val_loss: 2.2276 - val_accuracy: 0.7073\n",
            "Epoch 931/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.6707e-04 - accuracy: 1.0000 - val_loss: 2.2303 - val_accuracy: 0.7073\n",
            "Epoch 932/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.9166e-04 - accuracy: 1.0000 - val_loss: 2.2328 - val_accuracy: 0.7073\n",
            "Epoch 933/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.7476e-04 - accuracy: 1.0000 - val_loss: 2.2383 - val_accuracy: 0.7073\n",
            "Epoch 934/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 3.6382e-04 - accuracy: 1.0000 - val_loss: 2.2403 - val_accuracy: 0.7073\n",
            "Epoch 935/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.6116e-04 - accuracy: 1.0000 - val_loss: 2.2422 - val_accuracy: 0.7073\n",
            "Epoch 936/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.7442e-04 - accuracy: 1.0000 - val_loss: 2.2465 - val_accuracy: 0.7073\n",
            "Epoch 937/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 3.5505e-04 - accuracy: 1.0000 - val_loss: 2.2478 - val_accuracy: 0.7073\n",
            "Epoch 938/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.5008e-04 - accuracy: 1.0000 - val_loss: 2.2505 - val_accuracy: 0.7073\n",
            "Epoch 939/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.4587e-04 - accuracy: 1.0000 - val_loss: 2.2521 - val_accuracy: 0.7073\n",
            "Epoch 940/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.4207e-04 - accuracy: 1.0000 - val_loss: 2.2542 - val_accuracy: 0.7073\n",
            "Epoch 941/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.4052e-04 - accuracy: 1.0000 - val_loss: 2.2568 - val_accuracy: 0.7073\n",
            "Epoch 942/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.3664e-04 - accuracy: 1.0000 - val_loss: 2.2598 - val_accuracy: 0.7073\n",
            "Epoch 943/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.3666e-04 - accuracy: 1.0000 - val_loss: 2.2610 - val_accuracy: 0.7073\n",
            "Epoch 944/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 3.3889e-04 - accuracy: 1.0000 - val_loss: 2.2614 - val_accuracy: 0.7073\n",
            "Epoch 945/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.4501e-04 - accuracy: 1.0000 - val_loss: 2.2658 - val_accuracy: 0.7073\n",
            "Epoch 946/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.3588e-04 - accuracy: 1.0000 - val_loss: 2.2689 - val_accuracy: 0.7073\n",
            "Epoch 947/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.2895e-04 - accuracy: 1.0000 - val_loss: 2.2712 - val_accuracy: 0.7073\n",
            "Epoch 948/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 3.2429e-04 - accuracy: 1.0000 - val_loss: 2.2746 - val_accuracy: 0.7073\n",
            "Epoch 949/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 3.2040e-04 - accuracy: 1.0000 - val_loss: 2.2774 - val_accuracy: 0.7073\n",
            "Epoch 950/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.2196e-04 - accuracy: 1.0000 - val_loss: 2.2828 - val_accuracy: 0.7073\n",
            "Epoch 951/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.4632e-04 - accuracy: 1.0000 - val_loss: 2.2800 - val_accuracy: 0.7073\n",
            "Epoch 952/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.2063e-04 - accuracy: 1.0000 - val_loss: 2.2824 - val_accuracy: 0.7073\n",
            "Epoch 953/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.1479e-04 - accuracy: 1.0000 - val_loss: 2.2856 - val_accuracy: 0.7073\n",
            "Epoch 954/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.1054e-04 - accuracy: 1.0000 - val_loss: 2.2882 - val_accuracy: 0.7073\n",
            "Epoch 955/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 3.1056e-04 - accuracy: 1.0000 - val_loss: 2.2864 - val_accuracy: 0.7073\n",
            "Epoch 956/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 3.0839e-04 - accuracy: 1.0000 - val_loss: 2.2907 - val_accuracy: 0.7073\n",
            "Epoch 957/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.1561e-04 - accuracy: 1.0000 - val_loss: 2.2917 - val_accuracy: 0.7073\n",
            "Epoch 958/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 3.0709e-04 - accuracy: 1.0000 - val_loss: 2.2929 - val_accuracy: 0.7073\n",
            "Epoch 959/1000\n",
            "246/246 [==============================] - 2s 7ms/step - loss: 3.0286e-04 - accuracy: 1.0000 - val_loss: 2.2976 - val_accuracy: 0.7073\n",
            "Epoch 960/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 3.0137e-04 - accuracy: 1.0000 - val_loss: 2.2997 - val_accuracy: 0.7073\n",
            "Epoch 961/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.9736e-04 - accuracy: 1.0000 - val_loss: 2.3020 - val_accuracy: 0.7073\n",
            "Epoch 962/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.9417e-04 - accuracy: 1.0000 - val_loss: 2.3037 - val_accuracy: 0.7073\n",
            "Epoch 963/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.9148e-04 - accuracy: 1.0000 - val_loss: 2.3063 - val_accuracy: 0.7073\n",
            "Epoch 964/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.8941e-04 - accuracy: 1.0000 - val_loss: 2.3044 - val_accuracy: 0.7073\n",
            "Epoch 965/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.8930e-04 - accuracy: 1.0000 - val_loss: 2.3069 - val_accuracy: 0.7073\n",
            "Epoch 966/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.8784e-04 - accuracy: 1.0000 - val_loss: 2.3103 - val_accuracy: 0.7073\n",
            "Epoch 967/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.8438e-04 - accuracy: 1.0000 - val_loss: 2.3129 - val_accuracy: 0.7073\n",
            "Epoch 968/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.9074e-04 - accuracy: 1.0000 - val_loss: 2.3128 - val_accuracy: 0.7073\n",
            "Epoch 969/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.8848e-04 - accuracy: 1.0000 - val_loss: 2.3172 - val_accuracy: 0.7073\n",
            "Epoch 970/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.8140e-04 - accuracy: 1.0000 - val_loss: 2.3185 - val_accuracy: 0.7073\n",
            "Epoch 971/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.8050e-04 - accuracy: 1.0000 - val_loss: 2.3222 - val_accuracy: 0.7073\n",
            "Epoch 972/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.7852e-04 - accuracy: 1.0000 - val_loss: 2.3246 - val_accuracy: 0.7073\n",
            "Epoch 973/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.7484e-04 - accuracy: 1.0000 - val_loss: 2.3267 - val_accuracy: 0.7073\n",
            "Epoch 974/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.7240e-04 - accuracy: 1.0000 - val_loss: 2.3281 - val_accuracy: 0.7073\n",
            "Epoch 975/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.6987e-04 - accuracy: 1.0000 - val_loss: 2.3282 - val_accuracy: 0.7073\n",
            "Epoch 976/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.8042e-04 - accuracy: 1.0000 - val_loss: 2.3323 - val_accuracy: 0.7073\n",
            "Epoch 977/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.7246e-04 - accuracy: 1.0000 - val_loss: 2.3335 - val_accuracy: 0.7073\n",
            "Epoch 978/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.7078e-04 - accuracy: 1.0000 - val_loss: 2.3347 - val_accuracy: 0.7073\n",
            "Epoch 979/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.6739e-04 - accuracy: 1.0000 - val_loss: 2.3367 - val_accuracy: 0.7073\n",
            "Epoch 980/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.6442e-04 - accuracy: 1.0000 - val_loss: 2.3377 - val_accuracy: 0.7073\n",
            "Epoch 981/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.6157e-04 - accuracy: 1.0000 - val_loss: 2.3366 - val_accuracy: 0.7073\n",
            "Epoch 982/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.7222e-04 - accuracy: 1.0000 - val_loss: 2.3405 - val_accuracy: 0.7073\n",
            "Epoch 983/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.6135e-04 - accuracy: 1.0000 - val_loss: 2.3432 - val_accuracy: 0.7073\n",
            "Epoch 984/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.5807e-04 - accuracy: 1.0000 - val_loss: 2.3455 - val_accuracy: 0.7073\n",
            "Epoch 985/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.5552e-04 - accuracy: 1.0000 - val_loss: 2.3482 - val_accuracy: 0.7073\n",
            "Epoch 986/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.5320e-04 - accuracy: 1.0000 - val_loss: 2.3503 - val_accuracy: 0.7073\n",
            "Epoch 987/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.5232e-04 - accuracy: 1.0000 - val_loss: 2.3517 - val_accuracy: 0.7073\n",
            "Epoch 988/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.5215e-04 - accuracy: 1.0000 - val_loss: 2.3533 - val_accuracy: 0.7073\n",
            "Epoch 989/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.5195e-04 - accuracy: 1.0000 - val_loss: 2.3551 - val_accuracy: 0.7073\n",
            "Epoch 990/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.4874e-04 - accuracy: 1.0000 - val_loss: 2.3571 - val_accuracy: 0.7073\n",
            "Epoch 991/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.4634e-04 - accuracy: 1.0000 - val_loss: 2.3593 - val_accuracy: 0.7073\n",
            "Epoch 992/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.4439e-04 - accuracy: 1.0000 - val_loss: 2.3616 - val_accuracy: 0.7073\n",
            "Epoch 993/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.4242e-04 - accuracy: 1.0000 - val_loss: 2.3627 - val_accuracy: 0.7073\n",
            "Epoch 994/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.4113e-04 - accuracy: 1.0000 - val_loss: 2.3650 - val_accuracy: 0.7073\n",
            "Epoch 995/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.4009e-04 - accuracy: 1.0000 - val_loss: 2.3672 - val_accuracy: 0.7073\n",
            "Epoch 996/1000\n",
            "246/246 [==============================] - 1s 6ms/step - loss: 2.3890e-04 - accuracy: 1.0000 - val_loss: 2.3659 - val_accuracy: 0.7073\n",
            "Epoch 997/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.4486e-04 - accuracy: 1.0000 - val_loss: 2.3711 - val_accuracy: 0.7073\n",
            "Epoch 998/1000\n",
            "246/246 [==============================] - 1s 5ms/step - loss: 2.6360e-04 - accuracy: 1.0000 - val_loss: 2.3683 - val_accuracy: 0.7073\n",
            "Epoch 999/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.4379e-04 - accuracy: 1.0000 - val_loss: 2.3704 - val_accuracy: 0.7073\n",
            "Epoch 1000/1000\n",
            "246/246 [==============================] - 2s 6ms/step - loss: 2.3684e-04 - accuracy: 1.0000 - val_loss: 2.3719 - val_accuracy: 0.7073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = list.history['accuracy']\n",
        "val_acc = list.history['val_accuracy']\n",
        "loss = list.history['loss']\n",
        "val_loss = list.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "b6299f33-92ca-4d08-f248-13032c151656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "1e610c69-33e5-44b0-e067-61323907a627"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "07d629af-389e-4327-b6b9-94e22bc7efc9"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45113438, 0.54886556]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "40e61efa-11a8-4da3-8d72-59bcd49547fa"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}